{"cells":[{"cell_type":"code","execution_count":null,"id":"332b9791","metadata":{"id":"332b9791"},"outputs":[],"source":["##install and import necessary modules\n","##this code was originally designed and run in google colab\n","##use outside of colab may require modification\n","##if using colab, you may need to restart your runtime after installing modules,\n","##depending on enviornment at time of code running.\n","\n","!pip install scikit-learn==1.5.2\n","!pip install tensorflow==2.12.1\n","!pip install xgboost==2.0.2\n","import numpy as np\n","import pandas as pd\n","import matplotlib.pyplot as plt\n","import xgboost as xgb\n","import seaborn as sn\n","import sys\n","import sklearn\n","from google.colab import drive\n","from sklearn.linear_model import LogisticRegression\n","from sklearn.model_selection import train_test_split\n","from sklearn.preprocessing import MinMaxScaler, StandardScaler\n","from sklearn.calibration import CalibratedClassifierCV, calibration_curve\n","from sklearn.utils import resample\n","from scipy.stats import mannwhitneyu\n","from IPython import display\n","from sklearn.metrics import roc_curve, auc, roc_auc_score, precision_recall_curve, recall_score, confusion_matrix, brier_score_loss, f1_score\n","\n","sn.set(style='whitegrid')\n","pd.set_option('display.max_columns', None)\n","\n","print(\"Python version:\", sys.version)\n","print(\"scikit-learn version:\", sklearn.__version__)\n","print(\"XGBoost version:\", xgb.__version__)\n","print(\"shap version:\", shap.__version__)"]},{"cell_type":"code","execution_count":null,"id":"Ik3aE1RPVETF","metadata":{"id":"Ik3aE1RPVETF"},"outputs":[],"source":["# #import your dataset\n","from google.colab import drive\n","##mount google drive if using in colab. Replace <MOUNT_POINT> with the directory where you want to mount the drive (e.g., /content/drive).\n","drive.mount('<MOUNT_POINT>')\n","\n","# Replace <YOUR_FILE_PATH> with the actual path inside your Google Drive (e.g., My Drive/FileNameHere).\n","file_path = '<MOUNT_POINT>/<YOUR_FILE_PATH>.csv'"]},{"cell_type":"code","execution_count":null,"id":"_uAaUKFV7USL","metadata":{"id":"_uAaUKFV7USL"},"outputs":[],"source":["##specify columns to load from your dataset.  We will only load the columns necessary for the score and the variables necessary for the ISS/TRISS comparisons\n","\n","columns_to_load = ['AGEYEARS', 'TOTALGCS', 'SBP'\n","                  , 'TEMPERATURE'\n","                  , 'PULSERATE', 'TRISS', 'TRISS_Death', 'MORTALITY', 'TRAUMATYPE'\n","                  , 'WEIGHT'\n","                  , 'ISS_05', 'NumberOfInjuries',\n","                   'IntracranialVascularInjury','BrainStemInjury','EDH','SAH','SDH','SkullFx','DAI','NeckVascularInjury','ThoracicVascularInjury','AeroDigestiveInjury',\n","                   'CardiacInjury','LungInjury','AbdominalVascular','RibFx','KidneyInjury','StomachInjury','SpleenInjury','UroGenInternalInjury','SCI','SpineFx',\n","                   'UEAmputation','UEVascularInjury','UELongBoneFx','LEVascularInjury','PelvicFx','LEAmputation','PancreasInjury','LELongBoneFx','LiverInjury',\n","                   'ColorectalInjury','SmallBowelInjury','IPH'\n","                   , 'SEX', 'ETHNICITY', 'PRIMARYMETHODPAYMENT', 'RACE'\n","                   ]"]},{"cell_type":"code","execution_count":null,"id":"a9e8e1be","metadata":{"id":"a9e8e1be"},"outputs":[],"source":["# Import data and specify missing values\n","data = pd.read_csv(file_path, na_values=['NA', 'N/A', 'NULL', ' ', '', '-99', '-98', '-99.0', '-99.00', '-98.0', '-98.00', 'NaN'], usecols=columns_to_load)\n","\n","\n","# Filter out rows where 'TRAUMATYPE' is 26, 'Other/unspecified', or 'Burn'\n","try:\n","  exclude_values = ['26', 'Other/unspecified', 'Burn']\n","  data = data[~data['TRAUMATYPE'].isin(exclude_values)]\n","except:\n","  pass\n","\n","##explicitly list variables that need to be present for inclusion and drop cases without these\n","##we cannot compare our score to ISS/TRISS without those metrics, and we need our target outcome mortality\n","required_vars = ['ISS_05', 'TRISS_Death', 'MORTALITY']\n","data = data.dropna(subset=required_vars)\n","\n","# Create ShockIndex with the required logic\n","data['ShockIndex'] = np.where(\n","    data['SBP'] == 0, 2.0,  # Case where SBP is 0 â†’ set ShockIndex to 2.0\n","    data['PULSERATE'] / data['SBP']  # Normal calculation\n",")\n","\n","# Set ShockIndex to NaN if PULSERATE or SBP is missing\n","data.loc[data['PULSERATE'].isna() | data['SBP'].isna(), 'ShockIndex'] = np.nan\n","\n","##reset indices of the df\n","data.reset_index(drop=True, inplace=True)"]},{"cell_type":"code","execution_count":null,"id":"522c0982","metadata":{"id":"522c0982"},"outputs":[],"source":["##verify data appears as intended\n","data.head()"]},{"cell_type":"code","execution_count":null,"id":"ab349743","metadata":{"id":"ab349743"},"outputs":[],"source":["##check for missing values\n","data.isnull().sum(axis=0)"]},{"cell_type":"code","execution_count":null,"id":"e0ad2ed6","metadata":{"id":"e0ad2ed6"},"outputs":[],"source":["##create a datafram of all complications/vars to remove later.  We can remove all of these from the X data set and pick one to be\n","#our Y dataset\n","\n","complications_df=pd.DataFrame()\n","complications_list= [\n","                    'MORTALITY', 'TRISS', 'SEX', 'PRIMARYMETHODPAYMENT', 'RACE', 'ETHNICITY', 'ISS_05'\n","                    ]\n","for c in complications_list:\n","    complications_df[c] = data[c]\n","complications_df"]},{"cell_type":"code","execution_count":null,"id":"8650e14e","metadata":{"id":"8650e14e"},"outputs":[],"source":["##this is where we choose our outcome variable, mortality, and give it its own dataframe\n","\n","Y_data = pd.DataFrame()\n","Y_data['MORTALITY'] = data['MORTALITY']\n","Y_data"]},{"cell_type":"code","execution_count":null,"id":"75be5241","metadata":{"id":"75be5241"},"outputs":[],"source":["##clean Y_data by replacing \"Yes\" and \"No\" vcalues with 0's and 1's\n","\n","Y_data['MORTALITY'] = Y_data['MORTALITY'].replace({'Yes': 1, 'No': 0})\n","Y_data"]},{"cell_type":"code","execution_count":null,"id":"90944eb8","metadata":{"id":"90944eb8"},"outputs":[],"source":["##now drop the outcome from our feature space as well as TRISS, since were using 1-TRISS (aka TRISS_Death) and this varibale is now useless\n","##also drop these vars that will be used for fairness assessment but will not be used in the model\n","X_data = data.drop(columns=['MORTALITY', 'TRISS', 'ETHNICITY', 'PRIMARYMETHODPAYMENT', 'RACE', 'SEX'])\n","X_data.shape"]},{"cell_type":"code","execution_count":null,"id":"72ac3fa7","metadata":{"id":"72ac3fa7"},"outputs":[],"source":["##ensure no missing outcome data\n","Missing_Y = Y_data.isnull().sum(axis=0)\n","Missing_Y"]},{"cell_type":"code","execution_count":null,"id":"b9270983","metadata":{"id":"b9270983"},"outputs":[],"source":["##If we have no missing values here, our data is clean\n","Y_clean=Y_data.copy()"]},{"cell_type":"code","source":["##if above check passes, outcome data is now clean\n","Missing_Y_clean = Y_clean.isnull().sum(axis=0)\n","Missing_Y_clean"],"metadata":{"id":"Qw2kkLmrAeIN"},"id":"Qw2kkLmrAeIN","execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"id":"088ce1ba","metadata":{"id":"088ce1ba"},"outputs":[],"source":["##check which variables in the input space have missing variables\n","\n","Missing = X_data.isnull().sum(axis=0)\n","Missing[Missing>0]"]},{"cell_type":"code","execution_count":null,"id":"qaR1MA4zQX5n","metadata":{"id":"qaR1MA4zQX5n"},"outputs":[],"source":["##order variables with missing data by percentage\n","\n","data_missing = (X_data.isnull().sum(axis=0)/X_data.shape[0]) * 100\n","data_missing"]},{"cell_type":"code","execution_count":null,"id":"FtR5sBNwQaDW","metadata":{"id":"FtR5sBNwQaDW"},"outputs":[],"source":["##display variables withOUT mising data\n","\n","data_missing[data_missing == 0].index"]},{"cell_type":"code","execution_count":null,"id":"jCvUHe_RQbym","metadata":{"id":"jCvUHe_RQbym"},"outputs":[],"source":["#remove the good columns (no missing values) from data_missing\n","\n","data_missing = data_missing.drop(data_missing[data_missing == 0].index)\n","data_missing"]},{"cell_type":"code","execution_count":null,"id":"5qbwbipXQdnA","metadata":{"id":"5qbwbipXQdnA"},"outputs":[],"source":["#sort this in ascending order\n","data_missing = data_missing.sort_values(ascending=False)\n","data_missing"]},{"cell_type":"code","execution_count":null,"id":"pvKzlMEpQfcT","metadata":{"id":"pvKzlMEpQfcT"},"outputs":[],"source":["##prepare to drop variables with >50% missing values\n","##tried different cutoffs for this (33%, 66%), but 50% yielded best results\n","\n","dropCutoff=50\n","bad_column_names = data_missing[data_missing >=dropCutoff].index\n","bad_column_names"]},{"cell_type":"code","execution_count":null,"id":"uMsxdfhfQg2M","metadata":{"id":"uMsxdfhfQg2M"},"outputs":[],"source":["##actually drop bad variables\n","X_data_new=X_data.drop(columns=bad_column_names, axis=1)\n","\n","##check for which variables still have missing data (<50% missing values)\n","Missing = X_data_new.isnull().sum(axis=0)\n","Missing[Missing>0]"]},{"cell_type":"code","execution_count":null,"id":"HIBPbQv8QifC","metadata":{"id":"HIBPbQv8QifC"},"outputs":[],"source":["#display columns with less than 50% missing that need to be cleaned\n","\n","to_be_cleaned_column_names = data_missing[data_missing <50].index\n","to_be_cleaned_column_names"]},{"cell_type":"code","source":["# Rename the 'TRAUMATYPE' column to 'Penetrating' and map the values to 0 and 1\n","X_data_new['Penetrating'] = X_data_new['TRAUMATYPE'].map({'Penetrating': 1, 'Blunt': 0})\n","\n","# Drop the old 'TRAUMATYPE' column\n","X_data_new.drop(columns=['TRAUMATYPE'], inplace=True)\n","\n","print(X_data_new.head())"],"metadata":{"id":"7yE_Bbh2Krf-"},"id":"7yE_Bbh2Krf-","execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Display the entire DataFrame without truncation\n","pd.set_option('display.max_columns', None)\n","\n","# Get column names and data types\n","columns_info = []\n","for column_name, dtype in zip(X_data_new.columns, X_data_new.dtypes):\n","    columns_info.append(f\"{column_name}: {dtype}\")\n","\n","formatted_columns_info = \"\\n\".join(columns_info)\n","\n","# Print column names and data types\n","print(\"Column Names and Data Types:\")\n","print(formatted_columns_info)"],"metadata":{"id":"wFSegzudKvdJ"},"id":"wFSegzudKvdJ","execution_count":null,"outputs":[]},{"cell_type":"code","source":["##convert No's and Yes's to 0's and 1's to minimize the amount of double variables (want to avoid Yes/Nos being converted to 1-hot variables)\n","\n","try:\n","    X_data_new= X_data_new.replace({True: 1, 'Yes': 1, \"Female\": 1, False: 0, 'No': 0, \"Male\": 0})\n","except:\n","    pass\n","\n","##drop any non blunt/penetrating mechanisms\n","try:\n","    X_data_new=X_data_new.drop(['TRAUMATYPE_26', 'TRAUMATYPE_Other/unspecified'], axis=1)\n","except:\n","    pass\n","\n","X_data_new.head()"],"metadata":{"id":"R76ukwXZKzCn"},"id":"R76ukwXZKzCn","execution_count":null,"outputs":[]},{"cell_type":"code","source":["##split into train, test, calibrate sets\n","X_train, X_test, Y_train, Y_test = train_test_split(X_data_new, Y_clean, test_size=0.2, random_state=0, stratify=Y_clean)\n","X_train_cal, X_val_cal, Y_train_cal, Y_val_cal = train_test_split(X_train, Y_train, test_size=0.2, random_state=0, stratify=Y_train)"],"metadata":{"id":"371pWrPZK8lB"},"id":"371pWrPZK8lB","execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"id":"b5ec271e","metadata":{"id":"b5ec271e"},"outputs":[],"source":["##perform median/mode imputation on the inputs vars that are missing\n","for c in to_be_cleaned_column_names:\n","    v = X_train[c]\n","    v_valid = v[~v.isnull()]\n","\n","    if v.dtype == np.dtype('O'):  # Categorical column\n","        mode_value = v_valid.value_counts().index[0]\n","        for df in [X_train, X_test, X_train_cal, X_val_cal]:\n","            df[c] = df[c].fillna(mode_value).astype(object)\n","\n","    else:  # Numeric column\n","        median_value = v_valid.median()\n","        for df in [X_train, X_test, X_train_cal, X_val_cal]:\n","            df[c] = df[c].fillna(median_value)\n"]},{"cell_type":"code","execution_count":null,"id":"31a5eafa","metadata":{"id":"31a5eafa"},"outputs":[],"source":["##now for one-hot encoding\n","\n","# Identify categorical columns from X_train only\n","categorical_column = [c for c in X_train_cal.columns if X_train_cal[c].dtype == np.dtype('O')]\n","\n","# Apply pd.get_dummies to training data\n","X_train_cal = pd.get_dummies(X_train_cal, columns=categorical_column, sparse=False)\n","\n","categorical_column"]},{"cell_type":"code","execution_count":null,"id":"iWR41vor-_Pu","metadata":{"id":"iWR41vor-_Pu"},"outputs":[],"source":["# Align test and validation sets to match training set columns\n","X_test = pd.get_dummies(X_test, columns=categorical_column, sparse=False)\n","X_val_cal = pd.get_dummies(X_val_cal, columns=categorical_column, sparse=False)\n","\n","# Ensure same columns across all datasets\n","X_test = X_test.reindex(columns=X_train.columns, fill_value=0)\n","X_val_cal = X_val_cal.reindex(columns=X_train.columns, fill_value=0)"]},{"cell_type":"code","execution_count":null,"id":"c14955b3","metadata":{"id":"c14955b3"},"outputs":[],"source":["#verify data appears as intended\n","X_train_cal.head()"]},{"cell_type":"code","execution_count":null,"id":"2727c717","metadata":{"id":"2727c717"},"outputs":[],"source":["##verify no missing data in any split dataset\n","print(X_train_cal.isnull().sum().sum())\n","print(X_test.isnull().sum().sum())\n","print(X_val_cal.isnull().sum().sum())"]},{"cell_type":"code","execution_count":null,"id":"3f17738d","metadata":{"id":"3f17738d"},"outputs":[],"source":["##final list of training columns\n","X_train_cal.columns"]},{"cell_type":"code","execution_count":null,"id":"2770257a","metadata":{"id":"2770257a"},"outputs":[],"source":["#verify data is intended size\n","X_test.shape"]},{"cell_type":"code","source":["##now with data cleaned, take comparison vars and move them to their own dataframe prior to dropping\n","new_to_drop = ['TRISS_Death', 'ISS_05']\n","\n","X_ISS=pd.DataFrame()\n","X_ISS['ISS']=X_test['ISS_05']\n","\n","X_TRISS=pd.DataFrame()\n","X_TRISS['TRISS']=X_test['TRISS_Death']"],"metadata":{"id":"o5lm5Yi4qbta"},"id":"o5lm5Yi4qbta","execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"id":"MkSkefq4RN9D","metadata":{"id":"MkSkefq4RN9D"},"outputs":[],"source":["##now drop those comparison vars from the data that will be fed to the model\n","X_train_cal.drop(columns=new_to_drop, inplace=True)\n","X_test.drop(columns=new_to_drop, inplace=True)\n","X_val_cal.drop(columns=new_to_drop, inplace=True)\n","\n","\n","##store copies of data as tensors\n","X_train_tensor=X_train_cal.copy()\n","Y_train_tensor=Y_train_cal.copy()\n","\n","X_val_tensor=X_val_cal.copy()\n","Y_val_tensor=Y_val_cal.copy()\n","\n","X_test_tensor=X_test.copy()\n","Y_test_tensor=Y_test.copy()"]},{"cell_type":"code","source":["##verify data appears as intended\n","X_test.head()"],"metadata":{"id":"0GKlKCuvKUnw"},"id":"0GKlKCuvKUnw","execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"id":"PYoFPWDoRPQW","metadata":{"id":"PYoFPWDoRPQW"},"outputs":[],"source":["##Next step is to normalize data\n","\n","scaler=StandardScaler()\n","#get the parameters of the transform\n","scaler.fit(X_train_cal)\n","\n","#normalize the features in the training set\n","X_train_s_cal = scaler.transform(X_train_cal)\n","#normalize the features in the test set\n","print(\"After train/test split, X_test shape:\", X_test.shape)\n","X_test_s = scaler.transform(X_test)\n","print(\"After scaling, X_test_s shape:\", X_test_s.shape)\n","#normalize the features in the val set\n","X_val_s_cal = scaler.transform(X_val_cal)"]},{"cell_type":"code","execution_count":null,"id":"vtemq7fdbjoE","metadata":{"id":"vtemq7fdbjoE"},"outputs":[],"source":["##now, fit model with hyperparameters based on other Jupyternotebook optimization\n","model_best_gb = xgb.XGBClassifier(random_state=0, colsample_bytree=0.6, learning_rate=0.1, max_depth=7, n_estimators=200, subsample=1.0)\n","model_best_gb.fit(X_train_s_cal, Y_train_cal)"]},{"cell_type":"code","execution_count":null,"id":"L9Wj3__pbnO6","metadata":{"id":"L9Wj3__pbnO6"},"outputs":[],"source":["# Get predicted probabilities for test set (evaluate model)\n","from sklearn.metrics import roc_curve, auc, precision_recall_curve, recall_score, confusion_matrix\n","\n","y_prob_gbo_mtp = model_best_gb.predict_proba(X_test_s)[:, 1]\n","\n","# Compute AUROC on test set\n","auroc_gbo = roc_auc_score(Y_test, y_prob_gbo_mtp)\n","print(f\"AUROC on the test set: {auroc_gbo}\")"]},{"cell_type":"code","execution_count":null,"id":"A82t-nm2qKYQ","metadata":{"id":"A82t-nm2qKYQ"},"outputs":[],"source":["# Calibrate the model on the validation set\n","calibrated_model = CalibratedClassifierCV(estimator=model_best_gb, method='isotonic', cv='prefit')\n","calibrated_model.fit(X_val_s_cal, Y_val_cal)"]},{"cell_type":"code","execution_count":null,"id":"AT5kTGp8qK0k","metadata":{"id":"AT5kTGp8qK0k"},"outputs":[],"source":["# Get predicted probabilities for test set (evaluate model)\n","y_prob_gbo_mtp = calibrated_model.predict_proba(X_test_s)[:, 1]\n","\n","# Compute AUROC on test set (calibrated)\n","auroc_gbo = roc_auc_score(Y_test, y_prob_gbo_mtp)\n","print(f\"AUROC on the test set: {auroc_gbo}\")"]},{"cell_type":"code","source":["from sklearn.linear_model import LogisticRegression\n","\n","# Fit logistic regression: Outcome ~ ISS\n","lr_iss = LogisticRegression()\n","lr_iss.fit(X_ISS.values.reshape(-1,1), Y_test)\n","\n","# Predict probabilities\n","iss_probs = lr_iss.predict_proba(X_ISS.values.reshape(-1,1))[:,1]"],"metadata":{"id":"3ip8mxCo6jvy"},"id":"3ip8mxCo6jvy","execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Define a function to help evaluate model performance for a specified subgroup\n","def evaluate_subgroup(mask, X_test_tensor, complications_df, calibrated_model, threshold=0.5):\n","    \"\"\"\n","    Evaluate model performance for a specified subgroup (e.g., males or females).\n","\n","    Parameters:\n","    - mask: boolean mask from complications_df\n","    - X_test_tensor: full test feature matrix (pandas DataFrame or array)\n","    - complications_df: full dataframe containing 'MORTALITY' and subgroup columns\n","    - calibrated_model: trained and calibrated model\n","    - threshold: classification threshold for computing F1, confusion matrix, etc.\n","\n","    Returns:\n","    - Dictionary of performance metrics\n","    \"\"\"\n","    # Subset the test features and labels\n","    X_sub = X_test_tensor[mask]\n","    y_true = complications_df.loc[mask, 'MORTALITY'].values\n","    y_prob = calibrated_model.predict_proba(X_sub)[:, 1]\n","\n","    # Primary metrics\n","    auroc = roc_auc_score(y_true, y_prob)\n","    brier = brier_score_loss(y_true, y_prob)\n","\n","    # Threshold-dependent metrics\n","    y_pred = (y_prob >= threshold).astype(int)\n","    f1 = f1_score(y_true, y_pred)\n","\n","    # Optional confusion matrix-derived stats\n","    cm = confusion_matrix(y_true, y_pred)\n","    tn, fp, fn, tp = cm.ravel()\n","    accuracy = (tp + tn) / (tp + tn + fp + fn)\n","    sensitivity = tp / (tp + fn) if (tp + fn) else 0\n","    specificity = tn / (tn + fp) if (tn + fp) else 0\n","    precision = tp / (tp + fp) if (tp + fp) else 0\n","    npv = tn / (tn + fn) if (tn + fn) else 0\n","\n","    return {\n","        \"AUROC\": auroc,\n","        \"Brier Score\": brier,\n","        \"F1 Score\": f1,\n","        \"Accuracy\": accuracy,\n","        \"Sensitivity (TPR)\": sensitivity,\n","        \"Specificity (TNR)\": specificity,\n","        \"Precision (PPV)\": precision,\n","        \"Negative Predictive Value (NPV)\": npv\n","    }"],"metadata":{"id":"Wkkvczcnq_aS"},"id":"Wkkvczcnq_aS","execution_count":null,"outputs":[]},{"cell_type":"code","source":["# === Define Paired Bootstrap Function to compare models in subgroups ===\n","def paired_bootstrap_auc_test(\n","    y_true, predA, predB, n_boot=2000, alpha=0.025, random_state=None\n","):\n","\n","    \"\"\"\n","    Perform a paired bootstrap hypothesis test to compare AUROC between two models.\n","\n","    Parameters:\n","    - y_true: array-like of true binary labels\n","    - predA: predicted probabilities from model A\n","    - predB: predicted probabilities from model B\n","    - n_boot: number of bootstrap iterations (default: 2000)\n","    - alpha: significance level for confidence intervals (default: 0.025 for 95% CI)\n","    - random_state: seed for reproducibility\n","\n","    Returns:\n","    - Dictionary of AUROC scores, confidence intervals, p-value, and other summary statistics\n","    \"\"\"\n","\n","    # Ensure inputs are numpy arrays\n","    y_true = np.asarray(y_true)\n","    predA = np.asarray(predA)\n","    predB = np.asarray(predB)\n","\n","    # Validate equal lengths of input arrays\n","    assert len(y_true) == len(predA) == len(predB), \"Arrays must be the same length.\"\n","    n = len(y_true)\n","\n","    # Compute baseline AUROC scores for both models\n","    aucA = roc_auc_score(y_true, predA)\n","    aucB = roc_auc_score(y_true, predB)\n","    baseline_diff = aucA - aucB\n","\n","    # Initialize RNG and result containers\n","    rng = np.random.default_rng(random_state)\n","    aucAs = np.zeros(n_boot)\n","    aucBs = np.zeros(n_boot)\n","    diffs = np.zeros(n_boot)\n","\n","    # Perform paired bootstrap resampling\n","    for i in range(n_boot):\n","        idx = rng.integers(0, n, size=n) # Sample with replacement\n","        try:\n","            # Compute AUROC for resampled subset\n","            aucAs[i] = roc_auc_score(y_true[idx], predA[idx])\n","            aucBs[i] = roc_auc_score(y_true[idx], predB[idx])\n","            diffs[i] = aucAs[i] - aucBs[i]\n","        except:\n","            # Handle edge cases (e.g., only one class in resample)\n","            aucAs[i] = aucBs[i] = diffs[i] = np.nan\n","\n","    # Remove any invalid (NaN) results\n","    aucAs = aucAs[~np.isnan(diffs)]\n","    aucBs = aucBs[~np.isnan(diffs)]\n","    diffs = diffs[~np.isnan(diffs)]\n","\n","    # Return summary statistics and bootstrap confidence intervals\n","    return {\n","        \"aucA\": aucA,\n","        \"aucB\": aucB,\n","        \"aucA_ci_lower\": np.percentile(aucAs, 100 * alpha),\n","        \"aucA_ci_upper\": np.percentile(aucAs, 100 * (1 - alpha)),\n","        \"aucB_ci_lower\": np.percentile(aucBs, 100 * alpha),\n","        \"aucB_ci_upper\": np.percentile(aucBs, 100 * (1 - alpha)),\n","        \"baseline_diff\": baseline_diff,\n","        \"mean_diff\": np.mean(diffs),\n","        \"diff_ci_lower\": np.percentile(diffs, 100 * alpha),\n","        \"diff_ci_upper\": np.percentile(diffs, 100 * (1 - alpha)),\n","        \"p_value\": min(1.0, 2 * min(np.mean(diffs < 0), np.mean(diffs > 0))),\n","        \"coverage\": (1 - alpha) * 100\n","    }\n"],"metadata":{"id":"BylLahDEF1g2"},"id":"BylLahDEF1g2","execution_count":null,"outputs":[]},{"cell_type":"code","source":["##Now were going to evaluate each subgroup against its counterpart\n","\n","# Step 1: Prepare complications_test_df with mortality mapped to 0/1\n","complications_test_df = complications_df.loc[X_test.index].copy()\n","complications_test_df['MORTALITY'] = complications_test_df['MORTALITY'].map({'No': 0, 'Yes': 1})\n","complications_test_df = complications_test_df.dropna(subset=['MORTALITY'])\n","y_true_all = complications_test_df['MORTALITY'].astype(int).values\n","\n","# Step 2: Generate model predictions (already trained + scaled)\n","X_test_scaled = scaler.transform(X_test_tensor)\n","y_prob_model = calibrated_model.predict_proba(X_test_scaled)[:, 1]\n","\n","# Step 3: Add predictions to dataframe\n","complications_test_df['y_true'] = y_true_all\n","complications_test_df['y_prob_model'] = y_prob_model\n","complications_test_df['y_prob_iss'] = iss_probs.flatten()\n","complications_test_df['y_prob_triss'] = X_TRISS.values.flatten()\n","\n","# Step 4: Evaluation function for any group\n","def evaluate_all_models(df, group_name):\n","    group_df = df[df['SEX'] == group_name]\n","    y_true = group_df['y_true']\n","\n","    return {\n","        'Group': group_name,\n","        'AUROC_ML': roc_auc_score(y_true, group_df['y_prob_model']),\n","        'AUROC_ISS': roc_auc_score(y_true, group_df['y_prob_iss']),\n","        'AUROC_TRISS': roc_auc_score(y_true, group_df['y_prob_triss']),\n","        'Brier_ML': brier_score_loss(y_true, group_df['y_prob_model']),\n","        'Brier_ISS': brier_score_loss(y_true, group_df['y_prob_iss']),\n","        'Brier_TRISS': brier_score_loss(y_true, group_df['y_prob_triss']),\n","        'N': len(group_df),\n","        'Positives': int((y_true == 1).sum()),\n","        'Negatives': int((y_true == 0).sum())\n","    }\n","\n","# Step 5: Run evaluation for Male and Female\n","results_male = evaluate_all_models(complications_test_df, 'Male')\n","results_female = evaluate_all_models(complications_test_df, 'Female')\n","\n","# Step 6: Display results\n","for result in [results_male, results_female]:\n","    print(f\"=== {result['Group']} ===\")\n","    print(f\"AUROC (ML):    {result['AUROC_ML']:.3f}\")\n","    print(f\"AUROC (ISS):   {result['AUROC_ISS']:.3f}\")\n","    print(f\"AUROC (TRISS): {result['AUROC_TRISS']:.3f}\")\n","    print(f\"Brier (ML):    {result['Brier_ML']:.3f}\")\n","    print(f\"Brier (ISS):   {result['Brier_ISS']:.3f}\")\n","    print(f\"Brier (TRISS): {result['Brier_TRISS']:.3f}\")\n","    print(f\"N:             {result['N']}\")\n","    print(f\"Positives:     {result['Positives']}\")\n","    print(f\"Negatives:     {result['Negatives']}\\n\")\n","\n","    # Calculate AUROC delta between Male and Female for each method\n","delta_auroc_model = results_male['AUROC_ML'] - results_female['AUROC_ML']\n","delta_auroc_iss = results_male['AUROC_ISS'] - results_female['AUROC_ISS']\n","delta_auroc_triss = results_male['AUROC_TRISS'] - results_female['AUROC_TRISS']\n","\n","# Print deltas\n","print(\"=== AUROC Deltas (Male - Female) ===\")\n","print(f\"Model: {delta_auroc_model:.4f}\")\n","print(f\"ISS:   {delta_auroc_iss:.4f}\")\n","print(f\"TRISS: {delta_auroc_triss:.4f}\")\n","##"],"metadata":{"id":"9Gl9fHrO0M4w"},"id":"9Gl9fHrO0M4w","execution_count":null,"outputs":[]},{"cell_type":"code","source":["##shorthand to subset the dataset by sex and check the size\n","\n","female_df= complications_test_df[complications_test_df['SEX'] == 'Female']\n","male_df= complications_test_df[complications_test_df['SEX'] == 'Male']\n","female_df.shape"],"metadata":{"id":"jKR6IAwcoPms"},"id":"jKR6IAwcoPms","execution_count":null,"outputs":[]},{"cell_type":"code","source":["##evaluate AUROCs in female subgroup\n","\n","##get predicted probs/true labels for each model\n","predicted_prob_iss_female=female_df['y_prob_iss']\n","predicted_prob_triss_female=female_df['y_prob_triss']\n","predicted_prob_gbo_female=female_df['y_prob_model']\n","true_label_female=female_df['y_true']\n","\n","# Calculate the FPR, TPR, and thresholds\n","fpr_iss_female, tpr_iss_female, thresholds_iss_female = roc_curve(true_label_female, predicted_prob_iss_female)\n","\n","##now TRISS\n","fpr_triss_female, tpr_triss_female, thresholds_triss_female = roc_curve(true_label_female, predicted_prob_triss_female)\n","\n","##and MLISS\n","fpr_gbo_female, tpr_gbo_female, thresholds_gbo_female = roc_curve(true_label_female, predicted_prob_gbo_female)\n","\n","# Calculate the area under the ROC curve (AUROC)\n","roc_auc_iss_female = auc(fpr_iss_female, tpr_iss_female)\n","\n","##now TRISS\n","roc_auc_triss_female = auc(fpr_triss_female, tpr_triss_female)\n","\n","##and MLISS\n","roc_auc_gbo_female = auc(fpr_gbo_female, tpr_gbo_female)\n","\n","# Plot ROC curve\n","plt.figure(figsize=(8, 8))\n","plt.plot(fpr_gbo_female, tpr_gbo_female, color='b', lw=2, label=f'ROC curve (area = {roc_auc_gbo_female:.3f})')\n","plt.plot(fpr_triss_female, tpr_triss_female, color='green', lw=2, label=f'ROC AUC TRISS = {roc_auc_triss_female:.3f}')\n","plt.plot(fpr_iss_female, tpr_iss_female, color='darkorange', lw=2, label=f'ROC AUC ISS = {roc_auc_iss_female:.3f}')\n","plt.plot([0, 1], [0, 1], color='black', lw=2, linestyle='--', label='Random')\n","plt.xlabel('False Positive Rate')\n","plt.ylabel('True Positive Rate')\n","plt.title('Receiver Operating Characteristic (ROC) Curve-Female')\n","plt.legend(loc='lower right')\n","plt.show()"],"metadata":{"id":"FmscpKHYc8Kh"},"id":"FmscpKHYc8Kh","execution_count":null,"outputs":[]},{"cell_type":"code","source":["##now lets define a function to generate reliability diagrams for each model\n","\n","def bootstrap_calibration_curve(y_true, y_prob, n_bins=10, n_boot=1000, random_state=None):\n","    \"\"\"\n","    1) Compute the original bin-based calibration curve.\n","    2) Bootstrap the dataset n_boot times, each time recalculating the bin-based\n","       fraction of positives (prob_true) and storing it.\n","    3) Return the original curve + 95% CI per bin (based on 2.5 and 97.5 percentiles).\n","    \"\"\"\n","    # -----------------------------\n","    # Original calibration curve\n","    # -----------------------------\n","    # prob_true_orig, prob_pred_orig = calibration_curve(...) does binning internally.\n","    # But we want to fix n_bins and ensure consistent binning across bootstraps.\n","    # We'll do a manual binning approach here to keep consistent bin boundaries.\n","\n","    # Define bin edges (equally spaced from 0 to 1)\n","    bin_edges = np.linspace(0, 1, n_bins + 1)\n","    # Digitize predicted probabilities\n","    bin_indices = np.digitize(y_prob, bin_edges) - 1\n","    bin_indices[bin_indices == n_bins] = n_bins - 1  # cap any == n_bins to last bin\n","\n","    # Prepare arrays to hold the original bin stats\n","    prob_pred_orig = np.zeros(n_bins)\n","    prob_true_orig = np.zeros(n_bins)\n","    counts_in_bin = np.zeros(n_bins, dtype=int)\n","\n","    # Fill in the stats for each bin\n","    for i in range(n_bins):\n","        mask = (bin_indices == i)\n","        counts_in_bin[i] = np.sum(mask)\n","        if counts_in_bin[i] > 0:\n","            prob_pred_orig[i] = np.mean(y_prob[mask])   # mean predicted prob in this bin\n","            prob_true_orig[i] = np.mean(y_true[mask])   # fraction of positives (actual)\n","        else:\n","            # If bin is empty, set to NaN\n","            prob_pred_orig[i] = np.nan\n","            prob_true_orig[i] = np.nan\n","\n","    # Remove empty bins (NaN) from the original arrays\n","    valid_mask = ~np.isnan(prob_pred_orig)\n","    prob_pred_orig = prob_pred_orig[valid_mask]\n","    prob_true_orig = prob_true_orig[valid_mask]\n","\n","    # -----------------------------\n","    # Bootstrap to get CIs\n","    # -----------------------------\n","    rng = np.random.RandomState(random_state) if random_state else np.random\n","\n","    # We'll store the fraction of positives (prob_true) for each bin in each bootstrap\n","    # but only for the bins that were valid in the original data\n","    boot_prob_true = np.zeros((n_boot, sum(valid_mask)))\n","\n","    n_data = len(y_true)\n","    data_idx = np.arange(n_data)\n","\n","    for b in range(n_boot):\n","        # Sample with replacement\n","        sample_indices = rng.randint(0, n_data, size=n_data)\n","        y_true_b = y_true[sample_indices]\n","        y_prob_b = y_prob[sample_indices]\n","\n","        # Repeat the binning steps\n","        bin_indices_b = np.digitize(y_prob_b, bin_edges) - 1\n","        bin_indices_b[bin_indices_b == n_bins] = n_bins - 1\n","\n","        prob_true_b = np.zeros(n_bins)\n","        for i in range(n_bins):\n","            mask_b = (bin_indices_b == i)\n","            if np.sum(mask_b) > 0:\n","                prob_true_b[i] = np.mean(y_true_b[mask_b])\n","            else:\n","                prob_true_b[i] = np.nan\n","\n","        # filter to only valid bins\n","        prob_true_b = prob_true_b[valid_mask]\n","        boot_prob_true[b, :] = prob_true_b\n","\n","    # Compute 2.5th and 97.5th percentile per bin (column-wise)\n","    lower_ci = np.nanpercentile(boot_prob_true, 2.5, axis=0)\n","    upper_ci = np.nanpercentile(boot_prob_true, 97.5, axis=0)\n","\n","    return prob_pred_orig, prob_true_orig, lower_ci, upper_ci\n","\n","# Extract predictions and true labels\n","y_true = np.array(female_df['y_true'])\n","\n","y_prob_gbo = np.array(female_df['y_prob_model'])\n","y_prob_triss = np.array(female_df['y_prob_triss'])\n","y_prob_iss = np.array(female_df['y_prob_iss'])\n","\n","# Helper function to get sorted calibration data\n","def get_bootstrap_calibration_data(y_true, y_prob, label, color, n_bins=10, n_boot=1000, random_state=42):\n","    prob_pred, prob_true, lower_ci, upper_ci = bootstrap_calibration_curve(\n","        y_true, y_prob, n_bins=n_bins, n_boot=n_boot, random_state=random_state\n","    )\n","    sort_idx = np.argsort(prob_pred)\n","    return {\n","        \"x\": prob_pred[sort_idx],\n","        \"y\": prob_true[sort_idx],\n","        \"lower\": lower_ci[sort_idx],\n","        \"upper\": upper_ci[sort_idx],\n","        \"label\": label,\n","        \"color\": color\n","    }\n","\n","# Get calibration data for each method\n","calib_gbo = get_bootstrap_calibration_data(y_true, y_prob_gbo, label=\"ML Model\", color='b')\n","calib_triss = get_bootstrap_calibration_data(y_true, y_prob_triss, label=\"TRISS\", color='green')\n","calib_iss = get_bootstrap_calibration_data(y_true, y_prob_iss, label=\"ISS\", color='darkorange')\n","\n","# Compute Brier Scores\n","brier_gbo = brier_score_loss(y_true, y_prob_gbo)\n","brier_triss = brier_score_loss(y_true, y_prob_triss)\n","brier_iss = brier_score_loss(y_true, y_prob_iss)\n","\n","# Print Brier scores\n","print(f\"Brier Score - ML Model: {brier_gbo:.4f}\")\n","print(f\"Brier Score - TRISS:     {brier_triss:.4f}\")\n","print(f\"Brier Score - ISS:       {brier_iss:.4f}\")\n","\n","# Plot the reliability diagram\n","plt.figure(figsize=(8, 6))\n","plt.plot([0, 1], [0, 1], 'k--', label='Perfect Calibration')\n","\n","##do this for all 3 models\n","for calib in [calib_gbo, calib_triss, calib_iss]:\n","    plt.plot(calib[\"x\"], calib[\"y\"], marker='o', label=f'{calib[\"label\"]}', color=calib[\"color\"])\n","    plt.fill_between(calib[\"x\"], calib[\"lower\"], calib[\"upper\"], color=calib[\"color\"], alpha=0.2)\n","\n","plt.xlabel('Mean Predicted Probability')\n","plt.ylabel('Observed Mortality Rate')\n","plt.title('Reliability Diagram with 95% CI - Female')\n","plt.legend(loc='best')\n","plt.xlim([0, 1])\n","plt.ylim([0, 1])\n","plt.grid(True)\n","plt.show()"],"metadata":{"id":"ebjswIl2j4rU"},"id":"ebjswIl2j4rU","execution_count":null,"outputs":[]},{"cell_type":"code","source":["##lets define a function to generate a decision curve for each model\n","\n","def net_benefit(y_true, y_prob, thresholds):\n","    \"\"\"\n","    NetBenefit = (TP/N) - (FP/N)*(threshold/(1-threshold))\n","    \"\"\"\n","    N = len(y_true)\n","    NB = []\n","    for t in thresholds:\n","        y_pred = (y_prob >= t).astype(int)\n","        TP = np.sum((y_true == 1) & (y_pred == 1))\n","        FP = np.sum((y_true == 0) & (y_pred == 1))\n","        if t == 1.0:\n","            nb_t = 0\n","        else:\n","            nb_t = (TP / N) - (FP / N) * (t / (1 - t))\n","        NB.append(nb_t)\n","    return NB\n","\n","# Thresholds for decision curve\n","decision_thresholds = np.linspace(0.0, 1.0, 101)\n","\n","# Make sure y_true and predicted probs are arrays\n","y_true_array_dc = np.array(female_df['y_true']).flatten()\n","y_prob_gbo_array_dc = np.array(female_df['y_prob_model'])\n","iss_probs_dc = np.array(female_df['y_prob_iss'])\n","X_TRISS_dc = female_df['y_prob_triss']\n","\n","# Net benefit for your new model\n","NB_model = net_benefit(y_true_array_dc, y_prob_gbo_array_dc, decision_thresholds)\n","\n","# # Net benefit for ISS (ISS predictions: X_ISS.values)\n","NB_ISS = net_benefit(y_true_array_dc, iss_probs_dc, decision_thresholds)\n","\n","# Net benefit for TRISS (TRISS predictions: X_TRISS.values)\n","NB_TRISS = net_benefit(y_true_array_dc, X_TRISS_dc.values.flatten(), decision_thresholds)\n","\n","# Net benefit for treat all and treat none\n","N = len(Y_test)\n","prevalence = np.mean(Y_test)  # fraction of positives\n","treat_all_nb = []\n","for t in decision_thresholds:\n","    if t == 1.0:\n","        treat_all_nb.append(0)\n","    else:\n","        treat_all_nb.append(prevalence - (1 - prevalence)*(t/(1-t)))\n","\n","treat_none_nb = np.zeros_like(decision_thresholds)\n","\n","# Plotting\n","plt.figure(figsize=(8, 6))\n","plt.plot(decision_thresholds, NB_model, label='New ML Model', color='b')\n","plt.plot(decision_thresholds, NB_ISS, label='ISS', color='darkorange')\n","plt.plot(decision_thresholds, NB_TRISS, label='TRISS', color='g')\n","plt.plot(decision_thresholds, treat_all_nb, label='Treat All', color='red', linestyle='--')\n","plt.plot(decision_thresholds, treat_none_nb, label='Treat None', color='grey', linestyle=':')\n","\n","plt.xlabel('Threshold Probability')\n","plt.ylabel('Net Benefit')\n","plt.title('Decision Curve -Female')\n","plt.legend(loc='best')\n","plt.ylim([-0.04, 0.04])\n","plt.xlim([0, 1.0])\n","plt.grid(True)\n","plt.show()"],"metadata":{"id":"nlsGTmrJgfHx"},"id":"nlsGTmrJgfHx","execution_count":null,"outputs":[]},{"cell_type":"code","source":["##now do paired bootstrap testing to compare MLISS predictions to ISS/TRISS in females\n","\n","# Create a dictionary mapping each comparator model (ISS, TRISS) to its predicted probabilities\n","pairs = {\n","    \"ISS\": female_df['y_prob_iss'],\n","    \"TRISS\": female_df['y_prob_triss']\n","}\n","\n","# Loop through each comparator (ISS and TRISS)\n","for var_name, var_array in pairs.items():\n","    results = paired_bootstrap_auc_test(\n","        y_true=female_df['y_true'],\n","        predA=female_df['y_prob_model'],\n","        predB=var_array,\n","        n_boot=2000,      # or more for higher precision\n","        alpha=(0.05/2),\n","        random_state=42\n","    )\n","    coverage_str = f\"{results['coverage']:.1f}%\"\n","\n","    # Print results comparing ML model to the current comparator (e.g., ISS or TRISS)\n","    print(f\"--- ML Model vs. {var_name} --- in female patients\")\n","    print(f\"AUC(ML) = {results['aucA']:.3f}, {coverage_str} CI: \"\n","          f\"[{results['aucA_ci_lower']:.3f}, {results['aucA_ci_upper']:.3f}]\")\n","    print(f\"AUC({var_name}) = {results['aucB']:.3f}, {coverage_str} CI: \"\n","          f\"[{results['aucB_ci_lower']:.3f}, {results['aucB_ci_upper']:.3f}]\")\n","    print(f\"AUC diff (ML - {var_name}) = {results['baseline_diff']:.4f}, {coverage_str} CI: \"\n","          f\"[{results['diff_ci_lower']:.4f}, {results['diff_ci_upper']:.4f}]\")\n","    print(f\"p-value = {results['p_value']:.4f}\\n\")\n"],"metadata":{"id":"JOX1MxgLGsDa"},"id":"JOX1MxgLGsDa","execution_count":null,"outputs":[]},{"cell_type":"code","source":["##now do paired bootstrap testing to compare MLISS predictions to ISS/TRISS in males\n","\n","# Create a dictionary mapping each comparator model (ISS, TRISS) to its predicted probabilities\n","pairs = {\n","    \"ISS\": male_df['y_prob_iss'],\n","    \"TRISS\": male_df['y_prob_triss']\n","}\n","# Loop through each comparator (ISS and TRISS)\n","for var_name, var_array in pairs.items():\n","    results = paired_bootstrap_auc_test(\n","        y_true=male_df['y_true'],\n","        predA=male_df['y_prob_model'],\n","        predB=var_array,\n","        n_boot=2000,      # or more for higher precision\n","        alpha=(0.05/2),\n","        random_state=42\n","    )\n","    coverage_str = f\"{results['coverage']:.1f}%\"\n","    # Print results comparing ML model to the current comparator (e.g., ISS or TRISS)\n","    print(f\"--- ML Model vs. {var_name} ---\")\n","    print(f\"AUC(ML) = {results['aucA']:.3f}, {coverage_str} CI: \"\n","          f\"[{results['aucA_ci_lower']:.3f}, {results['aucA_ci_upper']:.3f}]\")\n","    print(f\"AUC({var_name}) = {results['aucB']:.3f}, {coverage_str} CI: \"\n","          f\"[{results['aucB_ci_lower']:.3f}, {results['aucB_ci_upper']:.3f}]\")\n","    print(f\"AUC diff (ML - {var_name}) = {results['baseline_diff']:.4f}, {coverage_str} CI: \"\n","          f\"[{results['diff_ci_lower']:.4f}, {results['diff_ci_upper']:.4f}]\")\n","    print(f\"p-value = {results['p_value']:.4f}\\n\")\n"],"metadata":{"id":"6317-KHJNb2e"},"id":"6317-KHJNb2e","execution_count":null,"outputs":[]},{"cell_type":"code","source":["##Now were going to evaluate each subgroup against its counterpart\n","\n","# Step 1: Prepare complications_test_df with mortality mapped to 0/1\n","complications_test_df = complications_df.loc[X_test.index].copy()\n","complications_test_df['MORTALITY'] = complications_test_df['MORTALITY'].map({'No': 0, 'Yes': 1})\n","\n","# Step 2: Ensure data types are numeric and clean\n","complications_test_df = complications_test_df.dropna(subset=['MORTALITY'])\n","y_true_all = complications_test_df['MORTALITY'].astype(int).values\n","\n","# Step 3: Scale the test data if not already done\n","X_test_scaled = scaler.transform(X_test_tensor)  # Make sure you use the same scaler from training\n","\n","# Step 4: Predict for entire test set once\n","y_prob_model = calibrated_model.predict_proba(X_test_scaled)[:, 1]\n","\n","# Step 5: Attach probabilities and true labels to complications_test_df for slicing\n","complications_test_df['y_true'] = y_true_all\n","complications_test_df['y_prob_model'] = y_prob_model\n","complications_test_df['y_prob_iss'] = iss_probs.flatten()\n","complications_test_df['y_prob_triss'] = X_TRISS.values.flatten()\n","\n","# Step 6: Define evaluation function\n","def evaluate_group(df, race_group_name, is_black=True):\n","    if is_black:\n","        group_df = df[df['RACE'] == race_group_name]\n","        group_label = race_group_name\n","    else:\n","        group_df = df[df['RACE'] != race_group_name]\n","        group_label = f\"Non-{race_group_name}\"\n","\n","    y_true = group_df['y_true']\n","\n","    return {\n","        'Group': group_label,\n","        'AUROC_ML': roc_auc_score(y_true, group_df['y_prob_model']),\n","        'AUROC_ISS': roc_auc_score(y_true, group_df['y_prob_iss']),\n","        'AUROC_TRISS': roc_auc_score(y_true, group_df['y_prob_triss']),\n","        'Brier_ML': brier_score_loss(y_true, group_df['y_prob_model']),\n","        'Brier_ISS': brier_score_loss(y_true, group_df['y_prob_iss']),\n","        'Brier_TRISS': brier_score_loss(y_true, group_df['y_prob_triss']),\n","        'N': len(group_df),\n","        'Positives': int((y_true == 1).sum()),\n","        'Negatives': int((y_true == 0).sum())\n","    }\n","\n","# Step 7: Run evaluation\n","results_black = evaluate_group(complications_test_df, 'Black', is_black=True)\n","results_nonblack = evaluate_group(complications_test_df, 'Black', is_black=False)\n","\n","\n","# Step 8: Print results\n","for result in [results_black, results_nonblack]:\n","    print(f\"=== {result['Group']} ===\")\n","    print(f\"AUROC (ML):    {result['AUROC_ML']:.3f}\")\n","    print(f\"AUROC (ISS):   {result['AUROC_ISS']:.3f}\")\n","    print(f\"AUROC (TRISS): {result['AUROC_TRISS']:.3f}\")\n","    print(f\"Brier (ML):    {result['Brier_ML']:.3f}\")\n","    print(f\"Brier (ISS):   {result['Brier_ISS']:.3f}\")\n","    print(f\"Brier (TRISS): {result['Brier_TRISS']:.3f}\")\n","    print(f\"N:             {result['N']}\")\n","    print(f\"Positives:     {result['Positives']}\")\n","    print(f\"Negatives:     {result['Negatives']}\\n\")\n","\n","      # Calculate AUROC delta between Black and Non-Black for each method\n","delta_auroc_model = results_black['AUROC_ML'] - results_nonblack['AUROC_ML']\n","delta_auroc_iss = results_black['AUROC_ISS'] - results_nonblack['AUROC_ISS']\n","delta_auroc_triss = results_black['AUROC_TRISS'] - results_nonblack['AUROC_TRISS']\n","\n","# Print deltas\n","print(\"=== AUROC Deltas (Black - Nonblack) ===\")\n","print(f\"Model: {delta_auroc_model:.4f}\")\n","print(f\"ISS:   {delta_auroc_iss:.4f}\")\n","print(f\"TRISS: {delta_auroc_triss:.4f}\")"],"metadata":{"id":"aQxK5J1D4vcC"},"id":"aQxK5J1D4vcC","execution_count":null,"outputs":[]},{"cell_type":"code","source":["##shorthand to subset the dataset by race and check the size\n","\n","black_df= complications_test_df[complications_test_df['RACE'] == 'Black']\n","nonblack_df= complications_test_df[complications_test_df['RACE'] != 'Black']\n","black_df.shape"],"metadata":{"id":"7Jq-yb0Hpc_D"},"id":"7Jq-yb0Hpc_D","execution_count":null,"outputs":[]},{"cell_type":"code","source":["##evaluate AUROCs in Black subgroup\n","\n","##get predicted probs/true labels for each model\n","predicted_prob_iss_black=black_df['y_prob_iss']\n","predicted_prob_triss_black=black_df['y_prob_triss']\n","predicted_prob_gbo_black=black_df['y_prob_model']\n","true_label_black=black_df['y_true']\n","\n","# Calculate the FPR, TPR, and thresholds\n","fpr_iss_black, tpr_iss_black, thresholds_iss_black = roc_curve(true_label_black, predicted_prob_iss_black)\n","\n","##now TRISS\n","fpr_triss_black, tpr_triss_black, thresholds_triss_black = roc_curve(true_label_black, predicted_prob_triss_black)\n","\n","##and MLISS\n","fpr_gbo_black, tpr_gbo_black, thresholds_gbo_black = roc_curve(true_label_black, predicted_prob_gbo_black)\n","\n","# Calculate the area under the ROC curve (AUROC)\n","roc_auc_iss_black = auc(fpr_iss_black, tpr_iss_black)\n","\n","##now TRISS\n","roc_auc_triss_black = auc(fpr_triss_black, tpr_triss_black)\n","\n","##and MLISS\n","roc_auc_gbo_black = auc(fpr_gbo_black, tpr_gbo_black)\n","\n","\n","# Plot ROC curve\n","plt.figure(figsize=(8, 8))\n","plt.plot(fpr_gbo_black, tpr_gbo_black, color='b', lw=2, label=f'ROC curve (area = {roc_auc_gbo_black:.3f})')\n","plt.plot(fpr_triss_black, tpr_triss_black, color='green', lw=2, label=f'ROC AUC TRISS = {roc_auc_triss_black:.3f}')\n","plt.plot(fpr_iss_black, tpr_iss_black, color='darkorange', lw=2, label=f'ROC AUC ISS = {roc_auc_iss_black:.3f}')\n","plt.plot([0, 1], [0, 1], color='black', lw=2, linestyle='--', label='Random')\n","plt.xlabel('False Positive Rate')\n","plt.ylabel('True Positive Rate')\n","plt.title('Receiver Operating Characteristic (ROC) Curve-Black')\n","plt.legend(loc='lower right')\n","plt.show()"],"metadata":{"id":"Bv3NYWZTk6IE"},"id":"Bv3NYWZTk6IE","execution_count":null,"outputs":[]},{"cell_type":"code","source":["##now reliability diagrams for all three methods in the Black subgroup\n","\n","# Extract predictions and true labels\n","y_true = np.array(black_df['y_true'])\n","y_prob_gbo = np.array(black_df['y_prob_model'])\n","y_prob_triss = np.array(black_df['y_prob_triss'])\n","y_prob_iss = np.array(black_df['y_prob_iss'])\n","\n","# Get calibration data for each method\n","calib_gbo = get_bootstrap_calibration_data(y_true, y_prob_gbo, label=\"ML Model\", color='b')\n","calib_triss = get_bootstrap_calibration_data(y_true, y_prob_triss, label=\"TRISS\", color='green')\n","calib_iss = get_bootstrap_calibration_data(y_true, y_prob_iss, label=\"ISS\", color='darkorange')\n","\n","# Compute Brier Scores\n","brier_gbo = brier_score_loss(y_true, y_prob_gbo)\n","brier_triss = brier_score_loss(y_true, y_prob_triss)\n","brier_iss = brier_score_loss(y_true, y_prob_iss)\n","\n","# Print Brier scores\n","print(f\"Brier Score - ML Model: {brier_gbo:.4f}\")\n","print(f\"Brier Score - TRISS:     {brier_triss:.4f}\")\n","print(f\"Brier Score - ISS:       {brier_iss:.4f}\")\n","\n","# Plot the reliability diagram\n","plt.figure(figsize=(8,6))\n","plt.plot([0, 1], [0, 1], 'k--', label='Perfect Calibration')\n","\n","for calib in [calib_gbo, calib_triss, calib_iss]:\n","    plt.plot(calib[\"x\"], calib[\"y\"], marker='o', label=calib[\"label\"], color=calib[\"color\"])\n","    plt.fill_between(calib[\"x\"], calib[\"lower\"], calib[\"upper\"], color=calib[\"color\"], alpha=0.2)\n","\n","plt.xlabel('Mean Predicted Probability')\n","plt.ylabel('Observed Mortality Rate')\n","plt.title('Reliability Diagram with 95% CI - Black Patients')\n","plt.legend(loc='best')\n","plt.xlim([0, 1])\n","plt.ylim([0, 1])\n","plt.grid(True)\n","plt.show()"],"metadata":{"id":"ITWvbE9TlCxg"},"id":"ITWvbE9TlCxg","execution_count":null,"outputs":[]},{"cell_type":"code","source":["##now decision curve analysis in the Black cohort\n","# ========================================\n","\n","\n","# Thresholds for decision curve\n","decision_thresholds = np.linspace(0.0, 1.0, 101)\n","\n","\n","# Make sure y_true and predicted probs are arrays\n","y_true_array_dc = np.array(black_df['y_true']).flatten()\n","y_prob_gbo_array_dc = np.array(black_df['y_prob_model'])\n","iss_probs_dc = np.array(black_df['y_prob_iss'])\n","X_TRISS_dc = black_df['y_prob_triss']\n","\n","# Net benefit for your new model\n","NB_model = net_benefit(y_true_array_dc, y_prob_gbo_array_dc, decision_thresholds)\n","\n","# # Net benefit for ISS (ISS predictions: X_ISS.values)\n","NB_ISS = net_benefit(y_true_array_dc, iss_probs_dc, decision_thresholds)\n","\n","# Net benefit for TRISS (TRISS predictions: X_TRISS.values)\n","NB_TRISS = net_benefit(y_true_array_dc, X_TRISS_dc.values.flatten(), decision_thresholds)\n","\n","# Net benefit for treat all and treat none\n","N = len(Y_test)\n","prevalence = np.mean(Y_test)  # fraction of positives\n","treat_all_nb = []\n","for t in decision_thresholds:\n","    if t == 1.0:\n","        treat_all_nb.append(0)\n","    else:\n","        treat_all_nb.append(prevalence - (1 - prevalence)*(t/(1-t)))\n","\n","treat_none_nb = np.zeros_like(decision_thresholds)\n","\n","# Plotting\n","plt.figure(figsize=(8, 6))\n","plt.plot(decision_thresholds, NB_model, label='New ML Model', color='b')\n","plt.plot(decision_thresholds, NB_ISS, label='ISS', color='darkorange')\n","plt.plot(decision_thresholds, NB_TRISS, label='TRISS', color='g')\n","plt.plot(decision_thresholds, treat_all_nb, label='Treat All', color='red', linestyle='--')\n","plt.plot(decision_thresholds, treat_none_nb, label='Treat None', color='grey', linestyle=':')\n","\n","plt.xlabel('Threshold Probability')\n","plt.ylabel('Net Benefit')\n","plt.title('Decision Curve Analysis-Black')\n","plt.legend(loc='best')\n","plt.ylim([-0.04, 0.04])\n","plt.xlim([0, 1.0])\n","plt.grid(True)\n","plt.show()"],"metadata":{"id":"LAXuYjTGpjGQ"},"id":"LAXuYjTGpjGQ","execution_count":null,"outputs":[]},{"cell_type":"code","source":["##now do paired bootstrap testing to compare MLISS predictions to ISS/TRISS in Black patients\n","\n","pairs = {\n","    \"ISS\": black_df['y_prob_iss'],\n","    \"TRISS\": black_df['y_prob_triss']\n","}\n","\n","# Create a dictionary mapping each comparator model (ISS, TRISS) to its predicted probabilities\n","for var_name, var_array in pairs.items():\n","    # Run paired bootstrap test comparing ML model to the current comparator\n","    results = paired_bootstrap_auc_test(\n","        y_true=black_df['y_true'],\n","        predA=black_df['y_prob_model'],\n","        predB=var_array,\n","        n_boot=2000,      # or more for higher precision\n","        alpha=(0.05/2),\n","        random_state=42\n","    )\n","    coverage_str = f\"{results['coverage']:.1f}%\"\n","    # Print results comparing ML model to the current comparator (e.g., ISS or TRISS)\n","    print(f\"--- ML Model vs. {var_name} --- in black patients\")\n","    print(f\"AUC(ML) = {results['aucA']:.3f}, {coverage_str} CI: \"\n","          f\"[{results['aucA_ci_lower']:.3f}, {results['aucA_ci_upper']:.3f}]\")\n","    print(f\"AUC({var_name}) = {results['aucB']:.3f}, {coverage_str} CI: \"\n","          f\"[{results['aucB_ci_lower']:.3f}, {results['aucB_ci_upper']:.3f}]\")\n","    print(f\"AUC diff (ML - {var_name}) = {results['baseline_diff']:.4f}, {coverage_str} CI: \"\n","          f\"[{results['diff_ci_lower']:.4f}, {results['diff_ci_upper']:.4f}]\")\n","    print(f\"p-value = {results['p_value']:.4f}\\n\")"],"metadata":{"id":"rtKPVZcoP40C"},"id":"rtKPVZcoP40C","execution_count":null,"outputs":[]},{"cell_type":"code","source":["##Now were going to evaluate each subgroup against its counterpart\n","\n","# Step 1: Prepare complications_test_df with mortality mapped to 0/1\n","complications_test_df = complications_df.loc[X_test.index].copy()\n","complications_test_df['MORTALITY'] = complications_test_df['MORTALITY'].map({'No': 0, 'Yes': 1})\n","complications_test_df = complications_test_df.dropna(subset=['MORTALITY'])\n","y_true_all = complications_test_df['MORTALITY'].astype(int).values\n","\n","# Step 2: Generate model predictions (already trained + scaled)\n","X_test_scaled = scaler.transform(X_test_tensor)\n","y_prob_model = calibrated_model.predict_proba(X_test_scaled)[:, 1]\n","\n","# Step 3: Add predictions to dataframe\n","complications_test_df['y_true'] = y_true_all\n","complications_test_df['y_prob_model'] = y_prob_model\n","complications_test_df['y_prob_iss'] = iss_probs.flatten()\n","complications_test_df['y_prob_triss'] = X_TRISS.values.flatten()\n","\n","# Step 4: Evaluation function for any group\n","def evaluate_all_models(df, group_name):\n","    group_df = df[df['ETHNICITY'] == group_name]\n","    y_true = group_df['y_true']\n","\n","    return {\n","        'Group': group_name,\n","        'AUROC_ML': roc_auc_score(y_true, group_df['y_prob_model']),\n","        'AUROC_ISS': roc_auc_score(y_true, group_df['y_prob_iss']),\n","        'AUROC_TRISS': roc_auc_score(y_true, group_df['y_prob_triss']),\n","        'Brier_ML': brier_score_loss(y_true, group_df['y_prob_model']),\n","        'Brier_ISS': brier_score_loss(y_true, group_df['y_prob_iss']),\n","        'Brier_TRISS': brier_score_loss(y_true, group_df['y_prob_triss']),\n","        'N': len(group_df),\n","        'Positives': int((y_true == 1).sum()),\n","        'Negatives': int((y_true == 0).sum())\n","    }\n","\n","# Step 5: Run evaluation for Hispanic v No\n","results_hisp = evaluate_all_models(complications_test_df, 'Hispanic or Latino')\n","results_nothisp = evaluate_all_models(complications_test_df, 'Not Hispanic or Latino')\n","\n","# Step 6: Display results\n","for result in [results_hisp, results_nothisp]:\n","    print(f\"=== {result['Group']} ===\")\n","    print(f\"AUROC (ML):    {result['AUROC_ML']:.3f}\")\n","    print(f\"AUROC (ISS):   {result['AUROC_ISS']:.3f}\")\n","    print(f\"AUROC (TRISS): {result['AUROC_TRISS']:.3f}\")\n","    print(f\"Brier (ML):    {result['Brier_ML']:.3f}\")\n","    print(f\"Brier (ISS):   {result['Brier_ISS']:.3f}\")\n","    print(f\"Brier (TRISS): {result['Brier_TRISS']:.3f}\")\n","    print(f\"N:             {result['N']}\")\n","    print(f\"Positives:     {result['Positives']}\")\n","    print(f\"Negatives:     {result['Negatives']}\\n\")\n","\n","    # Calculate AUROC delta between Male and Female for each method\n","delta_auroc_model = results_hisp['AUROC_ML'] - results_nothisp['AUROC_ML']\n","delta_auroc_iss = results_hisp['AUROC_ISS'] - results_nothisp['AUROC_ISS']\n","delta_auroc_triss = results_hisp['AUROC_TRISS'] - results_nothisp['AUROC_TRISS']\n","\n","# Print deltas\n","print(\"=== AUROC Deltas (Hisp - Not hisp) ===\")\n","print(f\"Model: {delta_auroc_model:.4f}\")\n","print(f\"ISS:   {delta_auroc_iss:.4f}\")\n","print(f\"TRISS: {delta_auroc_triss:.4f}\")\n"],"metadata":{"id":"BVWzYfw_AAkp"},"id":"BVWzYfw_AAkp","execution_count":null,"outputs":[]},{"cell_type":"code","source":["##shorthand to subset the dataset by ethnicity and check the size\n","hisp_df= complications_test_df[complications_test_df['ETHNICITY'] == 'Hispanic or Latino']\n","nonhisp_df= complications_test_df[complications_test_df['ETHNICITY'] != 'Hispanic or Latino']\n","hisp_df.shape"],"metadata":{"id":"dDZ2Ma9YQQUf"},"id":"dDZ2Ma9YQQUf","execution_count":null,"outputs":[]},{"cell_type":"code","source":["##evaluate AUROCs in Hispanic subgroup\n","\n","##get predicted probs/true labels for each model\n","predicted_prob_iss_hispanic=hisp_df['y_prob_iss']\n","predicted_prob_triss_hispanic=hisp_df['y_prob_triss']\n","predicted_prob_gbo_hispanic=hisp_df['y_prob_model']\n","true_label_hispanic=hisp_df['y_true']\n","\n","# Calculate the FPR, TPR, and thresholds\n","fpr_iss_hispanic, tpr_iss_hispanic, thresholds_iss_hispanic = roc_curve(true_label_hispanic, predicted_prob_iss_hispanic)\n","\n","##now TRISS\n","fpr_triss_hispanic, tpr_triss_hispanic, thresholds_triss_hispanic = roc_curve(true_label_hispanic, predicted_prob_triss_hispanic)\n","\n","##and MLISS\n","fpr_gbo_hispanic, tpr_gbo_hispanic, thresholds_gbo_hispanic = roc_curve(true_label_hispanic, predicted_prob_gbo_hispanic)\n","\n","# Calculate the area under the ROC curve (AUROC)\n","roc_auc_iss_hispanic = auc(fpr_iss_hispanic, tpr_iss_hispanic)\n","\n","##now TRISS\n","roc_auc_triss_hispanic = auc(fpr_triss_hispanic, tpr_triss_hispanic)\n","\n","##and MLISS\n","roc_auc_gbo_hispanic = auc(fpr_gbo_hispanic, tpr_gbo_hispanic)\n","\n","\n","# Plot ROC curve\n","plt.figure(figsize=(8, 8))\n","plt.plot(fpr_gbo_hispanic, tpr_gbo_hispanic, color='b', lw=2, label=f'ROC curve (area = {roc_auc_gbo_hispanic:.3f})')\n","plt.plot(fpr_triss_hispanic, tpr_triss_hispanic, color='green', lw=2, label=f'ROC AUC TRISS = {roc_auc_triss_hispanic:.3f}')\n","plt.plot(fpr_iss_hispanic, tpr_iss_hispanic, color='darkorange', lw=2, label=f'ROC AUC ISS = {roc_auc_iss_hispanic:.3f}')\n","plt.plot([0, 1], [0, 1], color='black', lw=2, linestyle='--', label='Random')\n","plt.xlabel('False Positive Rate')\n","plt.ylabel('True Positive Rate')\n","plt.title('Receiver Operating Characteristic (ROC) Curve-Hispanic')\n","plt.legend(loc='lower right')\n","plt.show()"],"metadata":{"id":"rmQJmpgFoVqw"},"id":"rmQJmpgFoVqw","execution_count":null,"outputs":[]},{"cell_type":"code","source":["##now reliability diagrams for all three methods in the Hispanic subgroup\n","\n","# Extract predictions and true labels\n","y_true = np.array(hisp_df['y_true'])\n","y_prob_gbo = np.array(hisp_df['y_prob_model'])\n","y_prob_triss = np.array(hisp_df['y_prob_triss'])\n","y_prob_iss = np.array(hisp_df['y_prob_iss'])\n","\n","# Get calibration data for each method\n","calib_gbo = get_bootstrap_calibration_data(y_true, y_prob_gbo, label=\"ML Model\", color='b')\n","calib_triss = get_bootstrap_calibration_data(y_true, y_prob_triss, label=\"TRISS\", color='green')\n","calib_iss = get_bootstrap_calibration_data(y_true, y_prob_iss, label=\"ISS\", color='darkorange')\n","\n","# Compute Brier Scores\n","brier_gbo = brier_score_loss(y_true, y_prob_gbo)\n","brier_triss = brier_score_loss(y_true, y_prob_triss)\n","brier_iss = brier_score_loss(y_true, y_prob_iss)\n","\n","# Print Brier scores\n","print(f\"Brier Score - ML Model: {brier_gbo:.4f}\")\n","print(f\"Brier Score - TRISS:     {brier_triss:.4f}\")\n","print(f\"Brier Score - ISS:       {brier_iss:.4f}\")\n","\n","# Plot the reliability diagram\n","plt.figure(figsize=(8,6))\n","plt.plot([0, 1], [0, 1], 'k--', label='Perfect Calibration')\n","\n","for calib in [calib_gbo, calib_triss, calib_iss]:\n","    plt.plot(calib[\"x\"], calib[\"y\"], marker='o', label=calib[\"label\"], color=calib[\"color\"])\n","    plt.fill_between(calib[\"x\"], calib[\"lower\"], calib[\"upper\"], color=calib[\"color\"], alpha=0.2)\n","\n","plt.xlabel('Mean Predicted Probability')\n","plt.ylabel('Observed Mortality Rate')\n","plt.title('Reliability Diagram with 95% CI - Hispanic Patients')\n","plt.legend(loc='best')\n","plt.xlim([0, 1])\n","plt.ylim([0, 1])\n","plt.grid(True)\n","plt.show()"],"metadata":{"id":"3WmQZDbGoc-m"},"id":"3WmQZDbGoc-m","execution_count":null,"outputs":[]},{"cell_type":"code","source":["##now decision curve analysis in the Hispanic cohort\n","# ========================================\n","\n","\n","# Thresholds for decision curve\n","decision_thresholds = np.linspace(0.0, 1.0, 101)\n","\n","\n","\n","# Make sure y_true and predicted probs are arrays\n","y_true_array_dc = np.array(hisp_df['y_true']).flatten()\n","y_prob_gbo_array_dc = np.array(hisp_df['y_prob_model'])\n","iss_probs_dc = np.array(hisp_df['y_prob_iss'])\n","X_TRISS_dc = hisp_df['y_prob_triss']\n","\n","# Net benefit for your new model\n","NB_model = net_benefit(y_true_array_dc, y_prob_gbo_array_dc, decision_thresholds)\n","\n","# # Net benefit for ISS (ISS predictions: X_ISS.values)\n","NB_ISS = net_benefit(y_true_array_dc, iss_probs_dc, decision_thresholds)\n","\n","# Net benefit for TRISS (TRISS predictions: X_TRISS.values)\n","NB_TRISS = net_benefit(y_true_array_dc, X_TRISS_dc.values.flatten(), decision_thresholds)\n","\n","# Net benefit for treat all and treat none\n","N = len(Y_test)\n","prevalence = np.mean(Y_test)  # fraction of positives\n","treat_all_nb = []\n","for t in decision_thresholds:\n","    if t == 1.0:\n","        treat_all_nb.append(0)\n","    else:\n","        treat_all_nb.append(prevalence - (1 - prevalence)*(t/(1-t)))\n","\n","treat_none_nb = np.zeros_like(decision_thresholds)\n","\n","# Plotting\n","plt.figure(figsize=(8, 6))\n","plt.plot(decision_thresholds, NB_model, label='New ML Model', color='b')\n","plt.plot(decision_thresholds, NB_ISS, label='ISS', color='darkorange')\n","plt.plot(decision_thresholds, NB_TRISS, label='TRISS', color='g')\n","plt.plot(decision_thresholds, treat_all_nb, label='Treat All', color='red', linestyle='--')\n","plt.plot(decision_thresholds, treat_none_nb, label='Treat None', color='grey', linestyle=':')\n","\n","plt.xlabel('Threshold Probability')\n","plt.ylabel('Net Benefit')\n","plt.title('Decision Curve Analysis-Hispanic')\n","plt.legend(loc='best')\n","plt.ylim([-0.04, 0.04])\n","plt.xlim([0, 1.0])\n","plt.grid(True)\n","plt.show()"],"metadata":{"id":"RS4ztRqtsaLV"},"id":"RS4ztRqtsaLV","execution_count":null,"outputs":[]},{"cell_type":"code","source":["##now do paired bootstrap testing to compare MLISS predictions to ISS/TRISS in Hispanic patients\n","\n","# Create a dictionary mapping each comparator model (ISS, TRISS) to its predicted probabilities\n","pairs = {\n","    \"ISS\": hisp_df['y_prob_iss'],\n","    \"TRISS\": hisp_df['y_prob_triss']\n","}\n","\n","# Loop through each comparator (ISS and TRISS)\n","for var_name, var_array in pairs.items():\n","\n","    # Run paired bootstrap test comparing ML model to the current comparator\n","    results = paired_bootstrap_auc_test(\n","        y_true=hisp_df['y_true'],\n","        predA=hisp_df['y_prob_model'],\n","        predB=var_array,\n","        n_boot=2000,      # or more for higher precision\n","        alpha=(0.05/2),\n","        random_state=42\n","    )\n","    coverage_str = f\"{results['coverage']:.1f}%\"\n","    # Print results comparing ML model to the current comparator (e.g., ISS or TRISS)\n","    print(f\"--- ML Model vs. {var_name} --- in Hispanic patients\")\n","    print(f\"AUC(ML) = {results['aucA']:.3f}, {coverage_str} CI: \"\n","          f\"[{results['aucA_ci_lower']:.3f}, {results['aucA_ci_upper']:.3f}]\")\n","    print(f\"AUC({var_name}) = {results['aucB']:.3f}, {coverage_str} CI: \"\n","          f\"[{results['aucB_ci_lower']:.3f}, {results['aucB_ci_upper']:.3f}]\")\n","    print(f\"AUC diff (ML - {var_name}) = {results['baseline_diff']:.4f}, {coverage_str} CI: \"\n","          f\"[{results['diff_ci_lower']:.4f}, {results['diff_ci_upper']:.4f}]\")\n","    print(f\"p-value = {results['p_value']:.4f}\\n\")"],"metadata":{"id":"g20UVXbLQTz-"},"id":"g20UVXbLQTz-","execution_count":null,"outputs":[]},{"cell_type":"code","source":["##Now were going to evaluate each subgroup against its counterpart\n","\n","# Step 1: Prepare complications_test_df with mortality mapped to 0/1\n","complications_test_df = complications_df.loc[X_test.index].copy()\n","complications_test_df['MORTALITY'] = complications_test_df['MORTALITY'].map({'No': 0, 'Yes': 1})\n","\n","# Step 2: Ensure data types are numeric and clean\n","complications_test_df = complications_test_df.dropna(subset=['MORTALITY'])\n","y_true_all = complications_test_df['MORTALITY'].astype(int).values\n","\n","# Step 3: Scale the test data if not already done\n","X_test_scaled = scaler.transform(X_test_tensor)  # Make sure you use the same scaler from training\n","\n","# Step 4: Predict for entire test set once\n","y_prob_model = calibrated_model.predict_proba(X_test_scaled)[:, 1]\n","\n","# Step 5: Attach probabilities and true labels to complications_test_df for slicing\n","complications_test_df['y_true'] = y_true_all\n","complications_test_df['y_prob_model'] = y_prob_model\n","complications_test_df['y_prob_iss'] = iss_probs.flatten()\n","complications_test_df['y_prob_triss'] = X_TRISS.values.flatten()\n","\n","# Step 6: Define evaluation function\n","def evaluate_group(df, pay_group_name, is_uninsured=True):\n","    if is_uninsured:\n","        group_df = df[df['PRIMARYMETHODPAYMENT'] == pay_group_name]\n","        group_label = pay_group_name\n","    else:\n","        group_df = df[df['PRIMARYMETHODPAYMENT'] != pay_group_name]\n","        group_label = f\"Non-{pay_group_name}\"\n","\n","    y_true = group_df['y_true']\n","\n","    return {\n","        'Group': group_label,\n","        'AUROC_ML': roc_auc_score(y_true, group_df['y_prob_model']),\n","        'AUROC_ISS': roc_auc_score(y_true, group_df['y_prob_iss']),\n","        'AUROC_TRISS': roc_auc_score(y_true, group_df['y_prob_triss']),\n","        'Brier_ML': brier_score_loss(y_true, group_df['y_prob_model']),\n","        'Brier_ISS': brier_score_loss(y_true, group_df['y_prob_iss']),\n","        'Brier_TRISS': brier_score_loss(y_true, group_df['y_prob_triss']),\n","        'N': len(group_df),\n","        'Positives': int((y_true == 1).sum()),\n","        'Negatives': int((y_true == 0).sum())\n","    }\n","\n","# Step 7: Run evaluation\n","results_uninsured = evaluate_group(complications_test_df, 'Self-Pay', is_uninsured=True)\n","results_insured = evaluate_group(complications_test_df, 'Self-Pay', is_uninsured=False)\n","\n","\n","# Step 8: Print results\n","for result in [results_uninsured, results_insured]:\n","    print(f\"=== {result['Group']} ===\")\n","    print(f\"AUROC (ML):    {result['AUROC_ML']:.3f}\")\n","    print(f\"AUROC (ISS):   {result['AUROC_ISS']:.3f}\")\n","    print(f\"AUROC (TRISS): {result['AUROC_TRISS']:.3f}\")\n","    print(f\"Brier (ML):    {result['Brier_ML']:.3f}\")\n","    print(f\"Brier (ISS):   {result['Brier_ISS']:.3f}\")\n","    print(f\"Brier (TRISS): {result['Brier_TRISS']:.3f}\")\n","    print(f\"N:             {result['N']}\")\n","    print(f\"Positives:     {result['Positives']}\")\n","    print(f\"Negatives:     {result['Negatives']}\\n\")\n","\n","      # Calculate AUROC delta between Male and Female for each method\n","delta_auroc_model = results_uninsured['AUROC_ML'] - results_insured['AUROC_ML']\n","delta_auroc_iss = results_uninsured['AUROC_ISS'] - results_insured['AUROC_ISS']\n","delta_auroc_triss = results_uninsured['AUROC_TRISS'] - results_insured['AUROC_TRISS']\n","\n","# Print deltas\n","print(\"=== AUROC Deltas (Insured - Uninsured) ===\")\n","print(f\"Model: {delta_auroc_model:.4f}\")\n","print(f\"ISS:   {delta_auroc_iss:.4f}\")\n","print(f\"TRISS: {delta_auroc_triss:.4f}\")"],"metadata":{"id":"CfaIcWEVB-6V"},"id":"CfaIcWEVB-6V","execution_count":null,"outputs":[]},{"cell_type":"code","source":["##shorthand to subset the dataset by insurance status and check the size\n","selfpay_df= complications_test_df[complications_test_df['PRIMARYMETHODPAYMENT'] == 'Self-Pay']\n","insured_df= complications_test_df[complications_test_df['PRIMARYMETHODPAYMENT'] != 'Self-Pay']\n","selfpay_df.shape"],"metadata":{"id":"CDutDOROQFR5"},"id":"CDutDOROQFR5","execution_count":null,"outputs":[]},{"cell_type":"code","source":["##evaluate AUROCs in uninsured subgroup\n","\n","##get predicted probs/true labels for each model\n","predicted_prob_iss_selfpay=selfpay_df['y_prob_iss']\n","predicted_prob_triss_selfpay=selfpay_df['y_prob_triss']\n","predicted_prob_gbo_selfpay=selfpay_df['y_prob_model']\n","true_label_selfpay=selfpay_df['y_true']\n","# Calculate the FPR, TPR, and thresholds\n","fpr_iss_selfpay, tpr_iss_selfpay, thresholds_iss_selfpay = roc_curve(true_label_selfpay, predicted_prob_iss_selfpay)\n","\n","##now TRISS\n","fpr_triss_selfpay, tpr_triss_selfpay, thresholds_triss_selfpay = roc_curve(true_label_selfpay, predicted_prob_triss_selfpay)\n","\n","##and MLISS\n","fpr_gbo_selfpay, tpr_gbo_selfpay, thresholds_gbo_selfpay = roc_curve(true_label_selfpay, predicted_prob_gbo_selfpay)\n","\n","# Calculate the area under the ROC curve (AUROC)\n","roc_auc_iss_selfpay = auc(fpr_iss_selfpay, tpr_iss_selfpay)\n","\n","##now TRISS\n","roc_auc_triss_selfpay = auc(fpr_triss_selfpay, tpr_triss_selfpay)\n","\n","##and MLISS\n","roc_auc_gbo_selfpay = auc(fpr_gbo_selfpay, tpr_gbo_selfpay)\n","\n","\n","\n","# Plot ROC curve\n","plt.figure(figsize=(8, 8))\n","plt.plot(fpr_gbo_selfpay, tpr_gbo_selfpay, color='b', lw=2, label=f'ROC curve (area = {roc_auc_gbo_selfpay:.3f})')\n","plt.plot(fpr_triss_selfpay, tpr_triss_selfpay, color='green', lw=2, label=f'ROC AUC TRISS = {roc_auc_triss_selfpay:.3f}')\n","plt.plot(fpr_iss_selfpay, tpr_iss_selfpay, color='darkorange', lw=2, label=f'ROC AUC ISS = {roc_auc_iss_selfpay:.3f}')\n","plt.plot([0, 1], [0, 1], color='black', lw=2, linestyle='--', label='Random')\n","plt.xlabel('False Positive Rate')\n","plt.ylabel('True Positive Rate')\n","plt.title('Receiver Operating Characteristic (ROC) Curve-Selfpay')\n","plt.legend(loc='lower right')\n","plt.show()"],"metadata":{"id":"xJ0WNFHusz-4"},"id":"xJ0WNFHusz-4","execution_count":null,"outputs":[]},{"cell_type":"code","source":["##now reliability diagrams for all three methods in the uninsured subgroup\n","\n","# Extract predictions and true labels\n","y_true = np.array(selfpay_df['y_true'])\n","y_prob_gbo = np.array(selfpay_df['y_prob_model'])\n","y_prob_triss = np.array(selfpay_df['y_prob_triss'])\n","y_prob_iss = np.array(selfpay_df['y_prob_iss'])\n","\n","# Get calibration data for each method\n","calib_gbo = get_bootstrap_calibration_data(y_true, y_prob_gbo, label=\"ML Model\", color='b')\n","calib_triss = get_bootstrap_calibration_data(y_true, y_prob_triss, label=\"TRISS\", color='green')\n","calib_iss = get_bootstrap_calibration_data(y_true, y_prob_iss, label=\"ISS\", color='darkorange')\n","\n","# Compute Brier Scores\n","brier_gbo = brier_score_loss(y_true, y_prob_gbo)\n","brier_triss = brier_score_loss(y_true, y_prob_triss)\n","brier_iss = brier_score_loss(y_true, y_prob_iss)\n","\n","# Print Brier scores\n","print(f\"Brier Score - ML Model: {brier_gbo:.4f}\")\n","print(f\"Brier Score - TRISS:     {brier_triss:.4f}\")\n","print(f\"Brier Score - ISS:       {brier_iss:.4f}\")\n","\n","# Plot the reliability diagram\n","plt.figure(figsize=(8,6))\n","plt.plot([0, 1], [0, 1], 'k--', label='Perfect Calibration')\n","\n","for calib in [calib_gbo, calib_triss, calib_iss]:\n","    plt.plot(calib[\"x\"], calib[\"y\"], marker='o', label=calib[\"label\"], color=calib[\"color\"])\n","    plt.fill_between(calib[\"x\"], calib[\"lower\"], calib[\"upper\"], color=calib[\"color\"], alpha=0.2)\n","\n","plt.xlabel('Mean Predicted Probability')\n","plt.ylabel('Observed Mortality Rate')\n","plt.title('Reliability Diagram with 95% CI - Self-pay Patients')\n","plt.legend(loc='best')\n","plt.xlim([0, 1])\n","plt.ylim([0, 1])\n","plt.grid(True)\n","plt.show()"],"metadata":{"id":"pti75R83tEgj"},"id":"pti75R83tEgj","execution_count":null,"outputs":[]},{"cell_type":"code","source":["##now decision curve analysis in the uninsured cohort\n","# ========================================\n","\n","\n","# Thresholds for decision curve\n","decision_thresholds = np.linspace(0.0, 1.0, 101)\n","\n","\n","\n","# Make sure y_true and predicted probs are arrays\n","y_true_array_dc = np.array(selfpay_df['y_true']).flatten()\n","y_prob_gbo_array_dc = np.array(selfpay_df['y_prob_model'])\n","iss_probs_dc = np.array(selfpay_df['y_prob_iss'])\n","X_TRISS_dc = selfpay_df['y_prob_triss']\n","\n","# Net benefit for your new model\n","NB_model = net_benefit(y_true_array_dc, y_prob_gbo_array_dc, decision_thresholds)\n","\n","# # Net benefit for ISS (ISS predictions: X_ISS.values)\n","NB_ISS = net_benefit(y_true_array_dc, iss_probs_dc, decision_thresholds)\n","\n","# Net benefit for TRISS (TRISS predictions: X_TRISS.values)\n","NB_TRISS = net_benefit(y_true_array_dc, X_TRISS_dc.values.flatten(), decision_thresholds)\n","\n","# Net benefit for treat all and treat none\n","N = len(Y_test)\n","prevalence = np.mean(Y_test)  # fraction of positives\n","treat_all_nb = []\n","for t in decision_thresholds:\n","    if t == 1.0:\n","        treat_all_nb.append(0)\n","    else:\n","        treat_all_nb.append(prevalence - (1 - prevalence)*(t/(1-t)))\n","\n","treat_none_nb = np.zeros_like(decision_thresholds)\n","\n","# Plotting\n","plt.figure(figsize=(8, 6))\n","plt.plot(decision_thresholds, NB_model, label='New ML Model', color='b')\n","plt.plot(decision_thresholds, NB_ISS, label='ISS', color='darkorange')\n","plt.plot(decision_thresholds, NB_TRISS, label='TRISS', color='g')\n","plt.plot(decision_thresholds, treat_all_nb, label='Treat All', color='red', linestyle='--')\n","plt.plot(decision_thresholds, treat_none_nb, label='Treat None', color='grey', linestyle=':')\n","\n","plt.xlabel('Threshold Probability')\n","plt.ylabel('Net Benefit')\n","plt.title('Decision Curve Analysis-Selfpay')\n","plt.legend(loc='best')\n","plt.ylim([-0.06, 0.06])\n","plt.xlim([0, 1.0])\n","plt.grid(True)\n","plt.show()"],"metadata":{"id":"4NdZLksZtTFg"},"id":"4NdZLksZtTFg","execution_count":null,"outputs":[]},{"cell_type":"code","source":["##now do paired bootstrap testing to compare MLISS predictions to ISS/TRISS in uninsured patients\n","\n","# Create a dictionary mapping each comparator model (ISS, TRISS) to its predicted probabilities\n","pairs = {\n","    \"ISS\": selfpay_df['y_prob_iss'],\n","    \"TRISS\": selfpay_df['y_prob_triss']\n","}\n","# Loop through each comparator (ISS and TRISS)\n","\n","for var_name, var_array in pairs.items():\n","    # Run paired bootstrap test comparing ML model to the current comparator\n","    results = paired_bootstrap_auc_test(\n","        y_true=selfpay_df['y_true'],\n","        predA=selfpay_df['y_prob_model'],\n","        predB=var_array,\n","        n_boot=2000,      # or more for higher precision\n","        alpha=(0.05/2),\n","        random_state=42\n","    )\n","    coverage_str = f\"{results['coverage']:.1f}%\"\n","    # Print results comparing ML model to the current comparator (e.g., ISS or TRISS)\n","    print(f\"--- ML Model vs. {var_name} --- in uninsured patients\")\n","    print(f\"AUC(ML) = {results['aucA']:.3f}, {coverage_str} CI: \"\n","          f\"[{results['aucA_ci_lower']:.3f}, {results['aucA_ci_upper']:.3f}]\")\n","    print(f\"AUC({var_name}) = {results['aucB']:.3f}, {coverage_str} CI: \"\n","          f\"[{results['aucB_ci_lower']:.3f}, {results['aucB_ci_upper']:.3f}]\")\n","    print(f\"AUC diff (ML - {var_name}) = {results['baseline_diff']:.4f}, {coverage_str} CI: \"\n","          f\"[{results['diff_ci_lower']:.4f}, {results['diff_ci_upper']:.4f}]\")\n","    print(f\"p-value = {results['p_value']:.4f}\\n\")"],"metadata":{"id":"qonZPBGlRd7_"},"id":"qonZPBGlRd7_","execution_count":null,"outputs":[]},{"cell_type":"code","source":["##Now were going to evaluate each ISS subgroup\n","\n","# Step 1: Prepare complications_test_df with mortality mapped to 0/1\n","complications_test_df = complications_df.loc[X_test.index].copy()\n","complications_test_df['MORTALITY'] = complications_test_df['MORTALITY'].map({'No': 0, 'Yes': 1})\n","\n","# Step 2: Ensure data types are numeric and clean\n","complications_test_df = complications_test_df.dropna(subset=['MORTALITY', 'ISS_05'])\n","y_true_all = complications_test_df['MORTALITY'].astype(int).values\n","\n","# Step 3: Scale the test data\n","X_test_scaled = scaler.transform(X_test_tensor)\n","\n","# Step 4: Predict for entire test set once\n","y_prob_model = calibrated_model.predict_proba(X_test_scaled)[:, 1]\n","\n","# Step 5: Attach predictions and labels\n","complications_test_df['y_true'] = y_true_all\n","complications_test_df['y_prob_model'] = y_prob_model\n","complications_test_df['y_prob_iss'] = iss_probs.flatten()\n","complications_test_df['y_prob_triss'] = X_TRISS.values.flatten()\n","\n","# Step 6: Define evaluation function for ISS group\n","def evaluate_iss_group(df, min_iss, max_iss=None):\n","    if max_iss is None:\n","        group_df = df[df['ISS_05'] > min_iss]\n","        label = f\"ISS > {min_iss}\"\n","    else:\n","        group_df = df[(df['ISS_05'] >= min_iss) & (df['ISS_05'] <= max_iss)]\n","        label = f\"ISS {min_iss}-{max_iss}\"\n","\n","    y_true = group_df['y_true']\n","    return {\n","        'Group': label,\n","        'AUROC_ML': roc_auc_score(y_true, group_df['y_prob_model']),\n","        'AUROC_ISS': roc_auc_score(y_true, group_df['y_prob_iss']),\n","        'AUROC_TRISS': roc_auc_score(y_true, group_df['y_prob_triss']),\n","        'Brier_ML': brier_score_loss(y_true, group_df['y_prob_model']),\n","        'Brier_ISS': brier_score_loss(y_true, group_df['y_prob_iss']),\n","        'Brier_TRISS': brier_score_loss(y_true, group_df['y_prob_triss']),\n","        'N': len(group_df),\n","        'Positives': int((y_true == 1).sum()),\n","        'Negatives': int((y_true == 0).sum())\n","    }\n","\n","# Step 7: Evaluate each ISS group\n","results_iss_under9 = evaluate_iss_group(complications_test_df, 0, 8)\n","results_iss_9_15 = evaluate_iss_group(complications_test_df, 9, 15)\n","results_iss_16_25 = evaluate_iss_group(complications_test_df, 16, 25)\n","results_iss_over25 = evaluate_iss_group(complications_test_df, 25, None)\n","\n","# Step 8: Print results\n","for result in [results_iss_under9, results_iss_9_15, results_iss_16_25, results_iss_over25]:\n","    print(f\"=== {result['Group']} ===\")\n","    print(f\"AUROC (ML):    {result['AUROC_ML']:.3f}\")\n","    print(f\"AUROC (ISS):   {result['AUROC_ISS']:.3f}\")\n","    print(f\"AUROC (TRISS): {result['AUROC_TRISS']:.3f}\")\n","    print(f\"Brier (ML):    {result['Brier_ML']:.3f}\")\n","    print(f\"Brier (ISS):   {result['Brier_ISS']:.3f}\")\n","    print(f\"Brier (TRISS): {result['Brier_TRISS']:.3f}\")\n","    print(f\"N:             {result['N']}\")\n","    print(f\"Positives:     {result['Positives']}\")\n","    print(f\"Negatives:     {result['Negatives']}\\n\")"],"metadata":{"id":"IW1C83ueQWtp"},"id":"IW1C83ueQWtp","execution_count":null,"outputs":[]},{"cell_type":"code","source":["##shorthand to subset the dataset by ISS group and check the size\n","issunder9_df = complications_test_df[complications_test_df['ISS_05'] < 9]\n","iss9to15_df = complications_test_df[(complications_test_df['ISS_05'] >= 9) & (complications_test_df['ISS_05'] <= 15)]\n","iss16to25_df = complications_test_df[(complications_test_df['ISS_05'] >= 16) & (complications_test_df['ISS_05'] <= 25)]\n","issover25_df = complications_test_df[complications_test_df['ISS_05'] > 25]\n","print(\"ISS<9 shape:\",issunder9_df.shape)\n","print(\"ISS 9-15 shape:\", iss9to15_df.shape)\n","print(\"ISS 16-25 shape:\", iss16to25_df.shape)\n","print(\"ISS>25 shape:\", issover25_df.shape)"],"metadata":{"id":"gqYoTj2sGgq1"},"id":"gqYoTj2sGgq1","execution_count":null,"outputs":[]},{"cell_type":"code","source":["##evaluate AUROCs in ISS subgroups\n","\n","##get predicted probs/true labels for each model\n","predicted_prob_iss_under9=issunder9_df['y_prob_iss']\n","predicted_prob_triss_under9=issunder9_df['y_prob_triss']\n","predicted_prob_gbo_under9=issunder9_df['y_prob_model']\n","true_label_under9=issunder9_df['y_true']\n","# Calculate the FPR, TPR, and thresholds\n","fpr_iss_under9, tpr_iss_under9, thresholds_iss_under9 = roc_curve(true_label_under9, predicted_prob_iss_under9)\n","\n","##now TRISS\n","fpr_triss_under9, tpr_triss_under9, thresholds_triss_under9 = roc_curve(true_label_under9, predicted_prob_triss_under9)\n","\n","##and MLISS\n","fpr_gbo_under9, tpr_gbo_under9, thresholds_gbo_under9 = roc_curve(true_label_under9, predicted_prob_gbo_under9)\n","\n","# Calculate the area under the ROC curve (AUROC)\n","roc_auc_iss_under9 = auc(fpr_iss_under9, tpr_iss_under9)\n","\n","##now TRISS\n","roc_auc_triss_under9 = auc(fpr_triss_under9, tpr_triss_under9)\n","\n","##and MLISS\n","roc_auc_gbo_under9 = auc(fpr_gbo_under9, tpr_gbo_under9)\n","\n","\n","\n","# Plot ROC curve\n","plt.figure(figsize=(8, 8))\n","plt.plot(fpr_gbo_under9, tpr_gbo_under9, color='b', lw=2, label=f'ROC curve (area = {roc_auc_gbo_under9:.3f})')\n","plt.plot(fpr_triss_under9, tpr_triss_under9, color='green', lw=2, label=f'ROC AUC TRISS = {roc_auc_triss_under9:.3f}')\n","plt.plot(fpr_iss_under9, tpr_iss_under9, color='darkorange', lw=2, label=f'ROC AUC ISS = {roc_auc_iss_under9:.3f}')\n","plt.plot([0, 1], [0, 1], color='black', lw=2, linestyle='--', label='Random')\n","plt.xlabel('False Positive Rate')\n","plt.ylabel('True Positive Rate')\n","plt.title('Receiver Operating Characteristic (ROC) Curve-ISS<9')\n","plt.legend(loc='lower right')\n","plt.show()"],"metadata":{"id":"CGHlTQvUGqsK"},"id":"CGHlTQvUGqsK","execution_count":null,"outputs":[]},{"cell_type":"code","source":["##now reliability diagrams for all three methods in the ISS <9 cohort\n","\n","# Extract predictions and true labels\n","y_true = np.array(issunder9_df['y_true'])\n","\n","y_prob_gbo = np.array(issunder9_df['y_prob_model'])\n","y_prob_triss = np.array(issunder9_df['y_prob_triss'])\n","y_prob_iss = np.array(issunder9_df['y_prob_iss'])\n","\n","# Report Brier scores\n","brier_gbo = brier_score_loss(y_true, y_prob_gbo)\n","brier_triss = brier_score_loss(y_true, y_prob_triss)\n","brier_iss = brier_score_loss(y_true, y_prob_iss)\n","\n","print(f\"Brier Score - ML Model : {brier_gbo:.4f}\")\n","print(f\"Brier Score - TRISS     : {brier_triss:.4f}\")\n","print(f\"Brier Score - ISS       : {brier_iss:.4f}\")\n","\n","# Helper function to get sorted calibration data\n","def get_bootstrap_calibration_data(y_true, y_prob, label, color, n_bins=10, n_boot=1000, random_state=42):\n","    prob_pred, prob_true, lower_ci, upper_ci = bootstrap_calibration_curve(\n","        y_true, y_prob, n_bins=n_bins, n_boot=n_boot, random_state=random_state\n","    )\n","    sort_idx = np.argsort(prob_pred)\n","    return {\n","        \"x\": prob_pred[sort_idx],\n","        \"y\": prob_true[sort_idx],\n","        \"lower\": lower_ci[sort_idx],\n","        \"upper\": upper_ci[sort_idx],\n","        \"label\": label,\n","        \"color\": color\n","    }\n","\n","# Get calibration data for each method\n","calib_gbo = get_bootstrap_calibration_data(y_true, y_prob_gbo, label=\"ML Model\", color='b')\n","calib_triss = get_bootstrap_calibration_data(y_true, y_prob_triss, label=\"TRISS\", color='green')\n","calib_iss = get_bootstrap_calibration_data(y_true, y_prob_iss, label=\"ISS\", color='darkorange')\n","\n","# Plot the reliability diagram\n","plt.figure(figsize=(8,6))\n","plt.plot([0, 1], [0, 1], 'k--', label='Perfect Calibration')\n","\n","for calib in [calib_gbo, calib_triss, calib_iss]:\n","    plt.plot(calib[\"x\"], calib[\"y\"], marker='o', label=f'{calib[\"label\"]}', color=calib[\"color\"])\n","    plt.fill_between(calib[\"x\"], calib[\"lower\"], calib[\"upper\"], color=calib[\"color\"], alpha=0.2)\n","\n","plt.xlabel('Mean Predicted Probability')\n","plt.ylabel('Observed Mortality Rate')\n","plt.title('Reliability Diagram (ISS < 9)')\n","plt.legend(loc='best')\n","plt.xlim([0, 1])\n","plt.ylim([0, 1])\n","plt.grid(True)\n","plt.show()"],"metadata":{"id":"FJk8a1J4GuXU"},"id":"FJk8a1J4GuXU","execution_count":null,"outputs":[]},{"cell_type":"code","source":["##now decision curve analysis in the ISS<9 cohort\n","# ========================================\n","\n","\n","# Thresholds for decision curve\n","decision_thresholds = np.linspace(0.0, 1.0, 101)\n","\n","# Make sure y_true and predicted probs are arrays\n","y_true_array_dc = np.array(issunder9_df['y_true']).flatten()\n","y_prob_gbo_array_dc = np.array(issunder9_df['y_prob_model'])\n","iss_probs_dc = np.array(issunder9_df['y_prob_iss'])\n","X_TRISS_dc = issunder9_df['y_prob_triss']\n","\n","# Net benefit for your new model\n","NB_model = net_benefit(y_true_array_dc, y_prob_gbo_array_dc, decision_thresholds)\n","\n","# # Net benefit for ISS (ISS predictions: X_ISS.values)\n","NB_ISS = net_benefit(y_true_array_dc, iss_probs_dc, decision_thresholds)\n","\n","# Net benefit for TRISS (TRISS predictions: X_TRISS.values)\n","NB_TRISS = net_benefit(y_true_array_dc, X_TRISS_dc.values.flatten(), decision_thresholds)\n","\n","# Net benefit for treat all and treat none\n","N = len(Y_test)\n","prevalence = np.mean(Y_test)  # fraction of positives\n","treat_all_nb = []\n","for t in decision_thresholds:\n","    if t == 1.0:\n","        treat_all_nb.append(0)\n","    else:\n","        treat_all_nb.append(prevalence - (1 - prevalence)*(t/(1-t)))\n","\n","treat_none_nb = np.zeros_like(decision_thresholds)\n","\n","# Plotting\n","plt.figure(figsize=(8, 6))\n","plt.plot(decision_thresholds, NB_model, label='New ML Model', color='b')\n","plt.plot(decision_thresholds, NB_ISS, label='ISS', color='darkorange')\n","plt.plot(decision_thresholds, NB_TRISS, label='TRISS', color='g')\n","plt.plot(decision_thresholds, treat_all_nb, label='Treat All', color='red', linestyle='--')\n","plt.plot(decision_thresholds, treat_none_nb, label='Treat None', color='grey', linestyle=':')\n","\n","plt.xlabel('Threshold Probability')\n","plt.ylabel('Net Benefit')\n","plt.title('Decision Curve Analysis-ISS <9')\n","plt.legend(loc='best')\n","plt.ylim([-0.01, 0.01])\n","plt.xlim([0, 1.0])\n","plt.grid(True)\n","plt.show()"],"metadata":{"id":"lMT3JuYYGuhV"},"id":"lMT3JuYYGuhV","execution_count":null,"outputs":[]},{"cell_type":"code","source":["##repeat for ISS9-15\n","\n","##get predicted probs and true labels\n","predicted_prob_iss_9to15 = iss9to15_df['y_prob_iss']\n","predicted_prob_triss_9to15 = iss9to15_df['y_prob_triss']\n","predicted_prob_gbo_9to15 = iss9to15_df['y_prob_model']\n","true_label_9to15 = iss9to15_df['y_true']\n","\n","#get FPR/TPR\n","fpr_iss_9to15, tpr_iss_9to15, _ = roc_curve(true_label_9to15, predicted_prob_iss_9to15)\n","fpr_triss_9to15, tpr_triss_9to15, _ = roc_curve(true_label_9to15, predicted_prob_triss_9to15)\n","fpr_gbo_9to15, tpr_gbo_9to15, _ = roc_curve(true_label_9to15, predicted_prob_gbo_9to15)\n","\n","#derive ROC\n","roc_auc_iss_9to15 = auc(fpr_iss_9to15, tpr_iss_9to15)\n","roc_auc_triss_9to15 = auc(fpr_triss_9to15, tpr_triss_9to15)\n","roc_auc_gbo_9to15 = auc(fpr_gbo_9to15, tpr_gbo_9to15)\n","\n","#plot\n","plt.figure(figsize=(8, 8))\n","plt.plot(fpr_gbo_9to15, tpr_gbo_9to15, color='b', lw=2, label=f'ML Model (AUC = {roc_auc_gbo_9to15:.3f})')\n","plt.plot(fpr_triss_9to15, tpr_triss_9to15, color='green', lw=2, label=f'TRISS (AUC = {roc_auc_triss_9to15:.3f})')\n","plt.plot(fpr_iss_9to15, tpr_iss_9to15, color='darkorange', lw=2, label=f'ISS (AUC = {roc_auc_iss_9to15:.3f})')\n","plt.plot([0, 1], [0, 1], color='black', lw=2, linestyle='--')\n","plt.xlabel('False Positive Rate')\n","plt.ylabel('True Positive Rate')\n","plt.title('ROC Curve - ISS 9â€“15')\n","plt.legend(loc='lower right')\n","plt.grid(True)\n","plt.show()"],"metadata":{"id":"aL4FtYO0Gujy"},"id":"aL4FtYO0Gujy","execution_count":null,"outputs":[]},{"cell_type":"code","source":["##now reliability diagrams for all three methods in the ISS 9-15 cohort\n","\n","# Extract predictions and true labels\n","y_true = np.array(iss9to15_df['y_true'])\n","\n","y_prob_gbo = np.array(iss9to15_df['y_prob_model'])\n","y_prob_triss = np.array(iss9to15_df['y_prob_triss'])\n","y_prob_iss = np.array(iss9to15_df['y_prob_iss'])\n","\n","# Report Brier scores\n","brier_gbo = brier_score_loss(y_true, y_prob_gbo)\n","brier_triss = brier_score_loss(y_true, y_prob_triss)\n","brier_iss = brier_score_loss(y_true, y_prob_iss)\n","\n","print(f\"Brier Score - ML Model : {brier_gbo:.4f}\")\n","print(f\"Brier Score - TRISS     : {brier_triss:.4f}\")\n","print(f\"Brier Score - ISS       : {brier_iss:.4f}\")\n","\n","# Helper function to get sorted calibration data\n","def get_bootstrap_calibration_data(y_true, y_prob, label, color, n_bins=10, n_boot=1000, random_state=42):\n","    prob_pred, prob_true, lower_ci, upper_ci = bootstrap_calibration_curve(\n","        y_true, y_prob, n_bins=n_bins, n_boot=n_boot, random_state=random_state\n","    )\n","    sort_idx = np.argsort(prob_pred)\n","    return {\n","        \"x\": prob_pred[sort_idx],\n","        \"y\": prob_true[sort_idx],\n","        \"lower\": lower_ci[sort_idx],\n","        \"upper\": upper_ci[sort_idx],\n","        \"label\": label,\n","        \"color\": color\n","    }\n","\n","# Get calibration data for each method\n","calib_gbo = get_bootstrap_calibration_data(y_true, y_prob_gbo, label=\"ML Model\", color='b')\n","calib_triss = get_bootstrap_calibration_data(y_true, y_prob_triss, label=\"TRISS\", color='green')\n","calib_iss = get_bootstrap_calibration_data(y_true, y_prob_iss, label=\"ISS\", color='darkorange')\n","\n","# Plot the reliability diagram\n","plt.figure(figsize=(8,6))\n","plt.plot([0, 1], [0, 1], 'k--', label='Perfect Calibration')\n","\n","for calib in [calib_gbo, calib_triss, calib_iss]:\n","    plt.plot(calib[\"x\"], calib[\"y\"], marker='o', label=f'{calib[\"label\"]}', color=calib[\"color\"])\n","    plt.fill_between(calib[\"x\"], calib[\"lower\"], calib[\"upper\"], color=calib[\"color\"], alpha=0.2)\n","\n","plt.xlabel('Mean Predicted Probability')\n","plt.ylabel('Observed Mortality Rate')\n","plt.title('Reliability Diagram (ISS 9-15)')\n","plt.legend(loc='best')\n","plt.xlim([0, 1])\n","plt.ylim([0, 1])\n","plt.grid(True)\n","plt.show()"],"metadata":{"id":"AUYta2bRGumI"},"id":"AUYta2bRGumI","execution_count":null,"outputs":[]},{"cell_type":"code","source":["##now decision curve analysis in the ISS 9-15 cohort\n","# ========================================\n","\n","# Thresholds for decision curve\n","decision_thresholds = np.linspace(0.0, 1.0, 101)\n","\n","# Make sure y_true and predicted probs are arrays\n","y_true_array_dc = np.array(iss9to15_df['y_true']).flatten()\n","y_prob_gbo_array_dc = np.array(iss9to15_df['y_prob_model'])\n","iss_probs_dc = np.array(iss9to15_df['y_prob_iss'])\n","X_TRISS_dc = iss9to15_df['y_prob_triss']\n","\n","# Net benefit for your new model\n","NB_model = net_benefit(y_true_array_dc, y_prob_gbo_array_dc, decision_thresholds)\n","\n","# # Net benefit for ISS (ISS predictions: X_ISS.values)\n","NB_ISS = net_benefit(y_true_array_dc, iss_probs_dc, decision_thresholds)\n","\n","# Net benefit for TRISS (TRISS predictions: X_TRISS.values)\n","NB_TRISS = net_benefit(y_true_array_dc, X_TRISS_dc.values.flatten(), decision_thresholds)\n","\n","# Net benefit for treat all and treat none\n","N = len(Y_test)\n","prevalence = np.mean(Y_test)  # fraction of positives\n","treat_all_nb = []\n","for t in decision_thresholds:\n","    if t == 1.0:\n","        treat_all_nb.append(0)\n","    else:\n","        treat_all_nb.append(prevalence - (1 - prevalence)*(t/(1-t)))\n","\n","treat_none_nb = np.zeros_like(decision_thresholds)\n","\n","# Plotting\n","plt.figure(figsize=(8, 6))\n","plt.plot(decision_thresholds, NB_model, label='New ML Model', color='b')\n","plt.plot(decision_thresholds, NB_ISS, label='ISS', color='darkorange')\n","plt.plot(decision_thresholds, NB_TRISS, label='TRISS', color='g')\n","plt.plot(decision_thresholds, treat_all_nb, label='Treat All', color='red', linestyle='--')\n","plt.plot(decision_thresholds, treat_none_nb, label='Treat None', color='grey', linestyle=':')\n","\n","plt.xlabel('Threshold Probability')\n","plt.ylabel('Net Benefit')\n","plt.title('Decision Curve Analysis-ISS 9to15')\n","plt.legend(loc='best')\n","plt.ylim([-0.02, 0.02])\n","plt.xlim([0, 1.0])\n","plt.grid(True)\n","plt.show()"],"metadata":{"id":"U2-cMOjCGuqN"},"id":"U2-cMOjCGuqN","execution_count":null,"outputs":[]},{"cell_type":"code","source":["##repeat for ISS16-25\n","\n","##get predicted probs and true labels\n","predicted_prob_iss_16to25 = iss16to25_df['y_prob_iss']\n","predicted_prob_triss_16to25 = iss16to25_df['y_prob_triss']\n","predicted_prob_gbo_16to25 = iss16to25_df['y_prob_model']\n","true_label_16to25 = iss16to25_df['y_true']\n","\n","#derive FPR, TPR\n","fpr_iss_16to25, tpr_iss_16to25, _ = roc_curve(true_label_16to25, predicted_prob_iss_16to25)\n","fpr_triss_16to25, tpr_triss_16to25, _ = roc_curve(true_label_16to25, predicted_prob_triss_16to25)\n","fpr_gbo_16to25, tpr_gbo_16to25, _ = roc_curve(true_label_16to25, predicted_prob_gbo_16to25)\n","\n","#derive ROC\n","roc_auc_iss_16to25 = auc(fpr_iss_16to25, tpr_iss_16to25)\n","roc_auc_triss_16to25 = auc(fpr_triss_16to25, tpr_triss_16to25)\n","roc_auc_gbo_16to25 = auc(fpr_gbo_16to25, tpr_gbo_16to25)\n","\n","#plot\n","plt.figure(figsize=(8, 8))\n","plt.plot(fpr_gbo_16to25, tpr_gbo_16to25, color='b', lw=2, label=f'ML Model (AUC = {roc_auc_gbo_16to25:.3f})')\n","plt.plot(fpr_triss_16to25, tpr_triss_16to25, color='green', lw=2, label=f'TRISS (AUC = {roc_auc_triss_16to25:.3f})')\n","plt.plot(fpr_iss_16to25, tpr_iss_16to25, color='darkorange', lw=2, label=f'ISS (AUC = {roc_auc_iss_16to25:.3f})')\n","plt.plot([0, 1], [0, 1], color='black', lw=2, linestyle='--')\n","plt.xlabel('False Positive Rate')\n","plt.ylabel('True Positive Rate')\n","plt.title('ROC Curve - ISS 16â€“25')\n","plt.legend(loc='lower right')\n","plt.grid(True)\n","plt.show()"],"metadata":{"id":"VbjfVv67Guuf"},"id":"VbjfVv67Guuf","execution_count":null,"outputs":[]},{"cell_type":"code","source":["##repeat RD for ISS 16-25\n","\n","# Extract predictions and true labels\n","y_true = np.array(iss16to25_df['y_true'])\n","\n","y_prob_gbo = np.array(iss16to25_df['y_prob_model'])\n","y_prob_triss = np.array(iss16to25_df['y_prob_triss'])\n","y_prob_iss = np.array(iss16to25_df['y_prob_iss'])\n","\n","# Report Brier scores\n","brier_gbo = brier_score_loss(y_true, y_prob_gbo)\n","brier_triss = brier_score_loss(y_true, y_prob_triss)\n","brier_iss = brier_score_loss(y_true, y_prob_iss)\n","\n","print(f\"Brier Score - ML Model : {brier_gbo:.4f}\")\n","print(f\"Brier Score - TRISS     : {brier_triss:.4f}\")\n","print(f\"Brier Score - ISS       : {brier_iss:.4f}\")\n","\n","# Helper function to get sorted calibration data\n","def get_bootstrap_calibration_data(y_true, y_prob, label, color, n_bins=10, n_boot=1000, random_state=42):\n","    prob_pred, prob_true, lower_ci, upper_ci = bootstrap_calibration_curve(\n","        y_true, y_prob, n_bins=n_bins, n_boot=n_boot, random_state=random_state\n","    )\n","    sort_idx = np.argsort(prob_pred)\n","    return {\n","        \"x\": prob_pred[sort_idx],\n","        \"y\": prob_true[sort_idx],\n","        \"lower\": lower_ci[sort_idx],\n","        \"upper\": upper_ci[sort_idx],\n","        \"label\": label,\n","        \"color\": color\n","    }\n","\n","# Get calibration data for each method\n","calib_gbo = get_bootstrap_calibration_data(y_true, y_prob_gbo, label=\"ML Model\", color='b')\n","calib_triss = get_bootstrap_calibration_data(y_true, y_prob_triss, label=\"TRISS\", color='green')\n","calib_iss = get_bootstrap_calibration_data(y_true, y_prob_iss, label=\"ISS\", color='darkorange')\n","\n","# Plot the reliability diagram\n","plt.figure(figsize=(8,6))\n","plt.plot([0, 1], [0, 1], 'k--', label='Perfect Calibration')\n","\n","for calib in [calib_gbo, calib_triss, calib_iss]:\n","    plt.plot(calib[\"x\"], calib[\"y\"], marker='o', label=f'{calib[\"label\"]}', color=calib[\"color\"])\n","    plt.fill_between(calib[\"x\"], calib[\"lower\"], calib[\"upper\"], color=calib[\"color\"], alpha=0.2)\n","\n","plt.xlabel('Mean Predicted Probability')\n","plt.ylabel('Observed Mortality Rate')\n","plt.title('Reliability Diagram (ISS 16-25)')\n","plt.legend(loc='best')\n","plt.xlim([0, 1])\n","plt.ylim([0, 1])\n","plt.grid(True)\n","plt.show()"],"metadata":{"id":"YFM8DW1EGuxy"},"id":"YFM8DW1EGuxy","execution_count":null,"outputs":[]},{"cell_type":"code","source":["#repeat DC for ISS 16-25\n","# ========================================\n","\n","\n","# Thresholds for decision curve\n","decision_thresholds = np.linspace(0.0, 1.0, 101)\n","\n","\n","\n","# Make sure y_true and predicted probs are arrays\n","y_true_array_dc = np.array(iss16to25_df['y_true']).flatten()\n","y_prob_gbo_array_dc = np.array(iss16to25_df['y_prob_model'])\n","iss_probs_dc = np.array(iss16to25_df['y_prob_iss'])\n","X_TRISS_dc = iss16to25_df['y_prob_triss']\n","\n","# Net benefit for your new model\n","NB_model = net_benefit(y_true_array_dc, y_prob_gbo_array_dc, decision_thresholds)\n","\n","# # Net benefit for ISS (ISS predictions: X_ISS.values)\n","NB_ISS = net_benefit(y_true_array_dc, iss_probs_dc, decision_thresholds)\n","\n","# Net benefit for TRISS (TRISS predictions: X_TRISS.values)\n","NB_TRISS = net_benefit(y_true_array_dc, X_TRISS_dc.values.flatten(), decision_thresholds)\n","\n","# Net benefit for treat all and treat none\n","N = len(Y_test)\n","prevalence = np.mean(Y_test)  # fraction of positives\n","treat_all_nb = []\n","for t in decision_thresholds:\n","    if t == 1.0:\n","        treat_all_nb.append(0)\n","    else:\n","        treat_all_nb.append(prevalence - (1 - prevalence)*(t/(1-t)))\n","\n","treat_none_nb = np.zeros_like(decision_thresholds)\n","\n","# Plotting\n","plt.figure(figsize=(8, 6))\n","plt.plot(decision_thresholds, NB_model, label='New ML Model', color='b')\n","plt.plot(decision_thresholds, NB_ISS, label='ISS', color='darkorange')\n","plt.plot(decision_thresholds, NB_TRISS, label='TRISS', color='g')\n","plt.plot(decision_thresholds, treat_all_nb, label='Treat All', color='red', linestyle='--')\n","plt.plot(decision_thresholds, treat_none_nb, label='Treat None', color='grey', linestyle=':')\n","\n","plt.xlabel('Threshold Probability')\n","plt.ylabel('Net Benefit')\n","plt.title('Decision Curve Analysis-ISS 16-25')\n","plt.legend(loc='best')\n","plt.ylim([-0.1, 0.1])\n","plt.xlim([0, 1.0])\n","plt.grid(True)\n","plt.show()"],"metadata":{"id":"9qWB4C--Gu01"},"id":"9qWB4C--Gu01","execution_count":null,"outputs":[]},{"cell_type":"code","source":["##repeat for ISS>25\n","\n","##get predicted probs and true labels\n","predicted_prob_iss_over25 = issover25_df['y_prob_iss']\n","predicted_prob_triss_over25 = issover25_df['y_prob_triss']\n","predicted_prob_gbo_over25 = issover25_df['y_prob_model']\n","true_label_over25 = issover25_df['y_true']\n","\n","##derive fpr, tpr\n","fpr_iss_over25, tpr_iss_over25, _ = roc_curve(true_label_over25, predicted_prob_iss_over25)\n","fpr_triss_over25, tpr_triss_over25, _ = roc_curve(true_label_over25, predicted_prob_triss_over25)\n","fpr_gbo_over25, tpr_gbo_over25, _ = roc_curve(true_label_over25, predicted_prob_gbo_over25)\n","\n","#derive ROCs\n","roc_auc_iss_over25 = auc(fpr_iss_over25, tpr_iss_over25)\n","roc_auc_triss_over25 = auc(fpr_triss_over25, tpr_triss_over25)\n","roc_auc_gbo_over25 = auc(fpr_gbo_over25, tpr_gbo_over25)\n","\n","#plot\n","plt.figure(figsize=(8, 8))\n","plt.plot(fpr_gbo_over25, tpr_gbo_over25, color='b', lw=2, label=f'ML Model (AUC = {roc_auc_gbo_over25:.3f})')\n","plt.plot(fpr_triss_over25, tpr_triss_over25, color='green', lw=2, label=f'TRISS (AUC = {roc_auc_triss_over25:.3f})')\n","plt.plot(fpr_iss_over25, tpr_iss_over25, color='darkorange', lw=2, label=f'ISS (AUC = {roc_auc_iss_over25:.3f})')\n","plt.plot([0, 1], [0, 1], color='black', lw=2, linestyle='--')\n","plt.xlabel('False Positive Rate')\n","plt.ylabel('True Positive Rate')\n","plt.title('ROC Curve - ISS > 25')\n","plt.legend(loc='lower right')\n","plt.grid(True)\n","plt.show()"],"metadata":{"id":"n4Kd7MIrHBv0"},"id":"n4Kd7MIrHBv0","execution_count":null,"outputs":[]},{"cell_type":"code","source":["##repeat RD for ISS>25\n","\n","# Extract predictions and true labels\n","y_true = np.array(issover25_df['y_true'])\n","\n","y_prob_gbo = np.array(issover25_df['y_prob_model'])\n","y_prob_triss = np.array(issover25_df['y_prob_triss'])\n","y_prob_iss = np.array(issover25_df['y_prob_iss'])\n","\n","# Report Brier scores\n","brier_gbo = brier_score_loss(y_true, y_prob_gbo)\n","brier_triss = brier_score_loss(y_true, y_prob_triss)\n","brier_iss = brier_score_loss(y_true, y_prob_iss)\n","\n","print(f\"Brier Score - ML Model : {brier_gbo:.4f}\")\n","print(f\"Brier Score - TRISS     : {brier_triss:.4f}\")\n","print(f\"Brier Score - ISS       : {brier_iss:.4f}\")\n","\n","# Helper function to get sorted calibration data\n","def get_bootstrap_calibration_data(y_true, y_prob, label, color, n_bins=10, n_boot=1000, random_state=42):\n","    prob_pred, prob_true, lower_ci, upper_ci = bootstrap_calibration_curve(\n","        y_true, y_prob, n_bins=n_bins, n_boot=n_boot, random_state=random_state\n","    )\n","    sort_idx = np.argsort(prob_pred)\n","    return {\n","        \"x\": prob_pred[sort_idx],\n","        \"y\": prob_true[sort_idx],\n","        \"lower\": lower_ci[sort_idx],\n","        \"upper\": upper_ci[sort_idx],\n","        \"label\": label,\n","        \"color\": color\n","    }\n","\n","# Get calibration data for each method\n","calib_gbo = get_bootstrap_calibration_data(y_true, y_prob_gbo, label=\"ML Model\", color='b')\n","calib_triss = get_bootstrap_calibration_data(y_true, y_prob_triss, label=\"TRISS\", color='green')\n","calib_iss = get_bootstrap_calibration_data(y_true, y_prob_iss, label=\"ISS\", color='darkorange')\n","\n","# Plot the reliability diagram\n","plt.figure(figsize=(8,6))\n","plt.plot([0, 1], [0, 1], 'k--', label='Perfect Calibration')\n","\n","for calib in [calib_gbo, calib_triss, calib_iss]:\n","    plt.plot(calib[\"x\"], calib[\"y\"], marker='o', label=f'{calib[\"label\"]}', color=calib[\"color\"])\n","    plt.fill_between(calib[\"x\"], calib[\"lower\"], calib[\"upper\"], color=calib[\"color\"], alpha=0.2)\n","\n","plt.xlabel('Mean Predicted Probability')\n","plt.ylabel('Observed Mortality Rate')\n","plt.title('Reliability Diagram (ISS > 25)')\n","plt.legend(loc='best')\n","plt.xlim([0, 1])\n","plt.ylim([0, 1])\n","plt.grid(True)\n","plt.show()"],"metadata":{"id":"Ld8gmzQEHByU"},"id":"Ld8gmzQEHByU","execution_count":null,"outputs":[]},{"cell_type":"code","source":["# repeat DC for ISS>25\n","# ========================================\n","\n","\n","# Thresholds for decision curve\n","decision_thresholds = np.linspace(0.0, 1.0, 101)\n","\n","\n","\n","# Make sure y_true and predicted probs are arrays\n","y_true_array_dc = np.array(issover25_df['y_true']).flatten()\n","y_prob_gbo_array_dc = np.array(issover25_df['y_prob_model'])\n","iss_probs_dc = np.array(issover25_df['y_prob_iss'])\n","X_TRISS_dc = issover25_df['y_prob_triss']\n","\n","# Net benefit for your new model\n","NB_model = net_benefit(y_true_array_dc, y_prob_gbo_array_dc, decision_thresholds)\n","\n","# # Net benefit for ISS (ISS predictions: X_ISS.values)\n","NB_ISS = net_benefit(y_true_array_dc, iss_probs_dc, decision_thresholds)\n","\n","# Net benefit for TRISS (TRISS predictions: X_TRISS.values)\n","NB_TRISS = net_benefit(y_true_array_dc, X_TRISS_dc.values.flatten(), decision_thresholds)\n","\n","# Net benefit for treat all and treat none\n","N = len(Y_test)\n","prevalence = np.mean(Y_test)  # fraction of positives\n","treat_all_nb = []\n","for t in decision_thresholds:\n","    if t == 1.0:\n","        treat_all_nb.append(0)\n","    else:\n","        treat_all_nb.append(prevalence - (1 - prevalence)*(t/(1-t)))\n","\n","treat_none_nb = np.zeros_like(decision_thresholds)\n","\n","# Plotting\n","plt.figure(figsize=(8, 6))\n","plt.plot(decision_thresholds, NB_model, label='New ML Model', color='b')\n","plt.plot(decision_thresholds, NB_ISS, label='ISS', color='darkorange')\n","plt.plot(decision_thresholds, NB_TRISS, label='TRISS', color='g')\n","plt.plot(decision_thresholds, treat_all_nb, label='Treat All', color='red', linestyle='--')\n","plt.plot(decision_thresholds, treat_none_nb, label='Treat None', color='grey', linestyle=':')\n","\n","plt.xlabel('Threshold Probability')\n","plt.ylabel('Net Benefit')\n","plt.title('Decision Curve Analysis-ISS >25')\n","plt.legend(loc='best')\n","plt.ylim([-0.3, 0.3])\n","plt.xlim([0, 1.0])\n","plt.grid(True)\n","plt.show()"],"metadata":{"id":"338Ea6u7UKtN"},"id":"338Ea6u7UKtN","execution_count":null,"outputs":[]},{"cell_type":"code","source":["##now lets compare performance of MLISS to both TRISS and ISS within eachn ISS cohort\n","\n","# === Define ISS bins ===\n","bins = [0, 9, 16, 26, np.inf]\n","labels = [\"<9\", \"9â€“15\", \"16â€“25\", \">25\"]\n","complications_test_df['ISS_BIN'] = pd.cut(complications_test_df['ISS_05'], bins=bins, labels=labels, right=False)\n","\n","# === Loop over bins and run paired bootstrap ===\n","for group in labels:\n","    df_sub = complications_test_df[complications_test_df['ISS_BIN'] == group]\n","    y_true = df_sub['y_true'].values\n","    ml_pred = df_sub['y_prob_model'].values\n","    iss_pred = df_sub['y_prob_iss'].values\n","    triss_pred = df_sub['y_prob_triss'].values\n","\n","    print(f\"\\n=== ISS Stratum: {group} ===\")\n","\n","    # ML vs ISS\n","    res_iss = paired_bootstrap_auc_test(y_true, ml_pred, iss_pred)\n","    print(f\"--- ML vs ISS ---\")\n","    print(f\"AUC(ML): {res_iss['aucA']:.3f}, {res_iss['coverage']}% CI: [{res_iss['aucA_ci_lower']:.3f}, {res_iss['aucA_ci_upper']:.3f}]\")\n","    print(f\"AUC(ISS): {res_iss['aucB']:.3f}, {res_iss['coverage']}% CI: [{res_iss['aucB_ci_lower']:.3f}, {res_iss['aucB_ci_upper']:.3f}]\")\n","    print(f\"Î”AUC: {res_iss['baseline_diff']:.4f}, CI: [{res_iss['diff_ci_lower']:.4f}, {res_iss['diff_ci_upper']:.4f}], p = {res_iss['p_value']:.4f}\")\n","\n","    # ML vs TRISS\n","    res_triss = paired_bootstrap_auc_test(y_true, ml_pred, triss_pred)\n","    print(f\"--- ML vs TRISS ---\")\n","    print(f\"AUC(ML): {res_triss['aucA']:.3f}, {res_triss['coverage']}% CI: [{res_triss['aucA_ci_lower']:.3f}, {res_triss['aucA_ci_upper']:.3f}]\")\n","    print(f\"AUC(TRISS): {res_triss['aucB']:.3f}, {res_triss['coverage']}% CI: [{res_triss['aucB_ci_lower']:.3f}, {res_triss['aucB_ci_upper']:.3f}]\")\n","    print(f\"Î”AUC: {res_triss['baseline_diff']:.4f}, CI: [{res_triss['diff_ci_lower']:.4f}, {res_triss['diff_ci_upper']:.4f}], p = {res_triss['p_value']:.4f}\")\n"],"metadata":{"id":"a5oIExF8RSs6"},"id":"a5oIExF8RSs6","execution_count":null,"outputs":[]}],"metadata":{"colab":{"provenance":[{"file_id":"1DYwnmjwYAdIuKZSkwpMlcAF8yUXEA0x7","timestamp":1728001604398}],"machine_shape":"hm","gpuType":"V6E1"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.5"},"accelerator":"TPU"},"nbformat":4,"nbformat_minor":5}
